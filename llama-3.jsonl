
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.831035510498006, "macro_f1": 0.8178139044233464}, {"mcc": 0.8070840651868535, "macro_f1": 0.7697355579344568}, {"mcc": 0.8132617732491604, "macro_f1": 0.7948441242478231}, {"mcc": 0.8054006400697953, "macro_f1": 0.7973164740960154}, {"mcc": 0.8232413576637203, "macro_f1": 0.8310879310881809}, {"mcc": 0.8290202029166756, "macro_f1": 0.8204567766657925}, {"mcc": 0.8041779047025892, "macro_f1": 0.7470895266228159}, {"mcc": 0.8271027408795156, "macro_f1": 0.8138209012588947}, {"mcc": 0.8123531504312801, "macro_f1": 0.8014533996669501}, {"mcc": 0.799330539006487, "macro_f1": 0.7950326220786055}], "total": {"test_mcc": 81.52007884604083, "test_mcc_se": 0.7142530844553647, "test_macro_f1": 79.88651218082882, "test_macro_f1_se": 1.5538401824833712}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5594879630210088, "macro_f1": 0.6874392200186845}, {"mcc": 0.5967778857595436, "macro_f1": 0.7273671756371828}, {"mcc": 0.6124957621530568, "macro_f1": 0.7410577943708224}, {"mcc": 0.572707025130146, "macro_f1": 0.7034759700170078}, {"mcc": 0.5918734992772995, "macro_f1": 0.723880825220863}, {"mcc": 0.6042589950657152, "macro_f1": 0.7326184227359119}, {"mcc": 0.5485886054547696, "macro_f1": 0.6969911746470484}, {"mcc": 0.5711202040727318, "macro_f1": 0.71678440829722}, {"mcc": 0.5948702173383693, "macro_f1": 0.7229421782499391}, {"mcc": 0.5609815854826808, "macro_f1": 0.7084886899824546}], "total": {"test_mcc": 58.131617427553216, "test_mcc_se": 1.3344497295526807, "test_macro_f1": 71.61045859177135, "test_macro_f1_se": 1.040095498754017}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.38545464252719097, "macro_f1": 0.39631377830186576}, {"mcc": 0.40581943564653195, "macro_f1": 0.40403465753341833}, {"mcc": 0.39445831047780516, "macro_f1": 0.40754393997191524}, {"mcc": 0.39743499532807947, "macro_f1": 0.4096548670235532}, {"mcc": 0.39375796710774297, "macro_f1": 0.3945694327361909}, {"mcc": 0.4021976378369631, "macro_f1": 0.4025528482421006}, {"mcc": 0.3977945287226328, "macro_f1": 0.39162088723492233}, {"mcc": 0.3937022987261286, "macro_f1": 0.3935834619773139}, {"mcc": 0.4105113142712406, "macro_f1": 0.4014862509173415}, {"mcc": 0.39624224145261666, "macro_f1": 0.40361779782934876}], "total": {"test_mcc": 39.773733720969325, "test_mcc_se": 0.4355595549673579, "test_macro_f1": 40.049779217679706, "test_macro_f1_se": 0.38106934395257847}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hotter-and-colder-sentiment", "task": "sentiment-classification", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.47259295840880566, "macro_f1": 0.6058652204009786}, {"mcc": 0.5213958406305134, "macro_f1": 0.6466587296631048}, {"mcc": 0.46402380775285484, "macro_f1": 0.629302041451781}, {"mcc": 0.4860123099736063, "macro_f1": 0.6083499552192257}, {"mcc": 0.4421367248686528, "macro_f1": 0.5327813850207068}, {"mcc": 0.419348069437277, "macro_f1": 0.5281209448181278}, {"mcc": 0.46031090476284714, "macro_f1": 0.609355544725274}, {"mcc": 0.4392327646599769, "macro_f1": 0.6009323012692017}, {"mcc": 0.4743520939061686, "macro_f1": 0.6020723941421157}, {"mcc": 0.49334988194355084, "macro_f1": 0.6268940720388403}], "total": {"test_mcc": 46.727553563442534, "test_mcc_se": 1.8261545509757549, "test_macro_f1": 59.90332588749357, "test_macro_f1_se": 2.412149266574589}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "sb10k", "task": "sentiment-classification", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5667681207068455, "macro_f1": 0.6868423172616883}, {"mcc": 0.6044954737300838, "macro_f1": 0.7249391018194581}, {"mcc": 0.6155701889421334, "macro_f1": 0.7411866990207515}, {"mcc": 0.571746473840972, "macro_f1": 0.6980359520803857}, {"mcc": 0.5864252237265001, "macro_f1": 0.7222693720420993}, {"mcc": 0.6042875708557434, "macro_f1": 0.7339675662617354}, {"mcc": 0.6375256585958349, "macro_f1": 0.7544807605823566}, {"mcc": 0.5476303271400936, "macro_f1": 0.6965641679258344}, {"mcc": 0.6675044011637579, "macro_f1": 0.777614766022341}, {"mcc": 0.6295737154361377, "macro_f1": 0.752357139863245}], "total": {"test_mcc": 60.31527154138102, "test_mcc_se": 2.249092554655961, "test_macro_f1": 72.88257842879896, "test_macro_f1_se": 1.798866148628506}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "dutch-social", "task": "sentiment-classification", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.17925017785421982, "macro_f1": 0.43067046441053264}, {"mcc": 0.13715910166774486, "macro_f1": 0.42098268029952507}, {"mcc": 0.17159251150893684, "macro_f1": 0.42869082777549594}, {"mcc": 0.16479756788468042, "macro_f1": 0.395244972186564}, {"mcc": 0.17268402900105015, "macro_f1": 0.42457117281918433}, {"mcc": 0.18008847891736796, "macro_f1": 0.4463410687751626}, {"mcc": 0.12476334987677405, "macro_f1": 0.39950973493540115}, {"mcc": 0.1960238776432071, "macro_f1": 0.4408734386573722}, {"mcc": 0.10987109412993748, "macro_f1": 0.4103709968390497}, {"mcc": 0.17253463898031424, "macro_f1": 0.34832688273854456}], "total": {"test_mcc": 16.087648274642326, "test_mcc_se": 1.7056622735614095, "test_macro_f1": 41.455822394368326, "test_macro_f1_se": 1.7660664037312808}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "sst5", "task": "sentiment-classification", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.67823307839436, "macro_f1": 0.6676107974138725}, {"mcc": 0.6946889406552362, "macro_f1": 0.6734393968843421}, {"mcc": 0.691996394814659, "macro_f1": 0.7079331112911244}, {"mcc": 0.7035006064862503, "macro_f1": 0.6671120803206044}, {"mcc": 0.6998279473421473, "macro_f1": 0.6867506200272882}, {"mcc": 0.6710544777445407, "macro_f1": 0.6845608636905728}, {"mcc": 0.7048886791438821, "macro_f1": 0.7029587815324101}, {"mcc": 0.6746994846151774, "macro_f1": 0.6644851379054125}, {"mcc": 0.697616158353881, "macro_f1": 0.6767566441251832}, {"mcc": 0.6964911872598182, "macro_f1": 0.6974092053120585}], "total": {"test_mcc": 69.12996954809951, "test_mcc_se": 0.7566400469150648, "test_macro_f1": 68.29016638502868, "test_macro_f1_se": 0.970476743674141}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "fosent", "task": "sentiment-classification", "dataset_languages": ["fo"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5759810163840613, "macro_f1": 0.7004281768679674}, {"mcc": 0.5319328951898249, "macro_f1": 0.6722456750874493}, {"mcc": 0.5106081012610056, "macro_f1": 0.6725941994485173}, {"mcc": 0.5717555879061577, "macro_f1": 0.7197585705751535}, {"mcc": 0.4725418679767775, "macro_f1": 0.6109807040841523}, {"mcc": 0.618177458284503, "macro_f1": 0.7371192736126906}, {"mcc": 0.5912814240971404, "macro_f1": 0.7173395893178364}, {"mcc": 0.6663108214244904, "macro_f1": 0.7831732014200515}, {"mcc": 0.6462438827216423, "macro_f1": 0.7685900317019837}, {"mcc": 0.6143250880358149, "macro_f1": 0.7316070631733282}], "total": {"test_mcc": 57.991581432814186, "test_mcc_se": 3.7734055207926063, "test_macro_f1": 71.13836485289131, "test_macro_f1_se": 3.122387080160535}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.7355864811133201, "micro_f1": 0.4494105226112969}, {"micro_f1_no_misc": 0.7889495663347255, "micro_f1": 0.6105610561056105}, {"micro_f1_no_misc": 0.7431141090500282, "micro_f1": 0.5267927501970056}, {"micro_f1_no_misc": 0.7236068328199383, "micro_f1": 0.5879837502672653}, {"micro_f1_no_misc": 0.8066066066066067, "micro_f1": 0.703318474492323}, {"micro_f1_no_misc": 0.7665832290362953, "micro_f1": 0.6532921810699589}, {"micro_f1_no_misc": 0.7737529691211401, "micro_f1": 0.6609888810030755}, {"micro_f1_no_misc": 0.7362569487337863, "micro_f1": 0.505503634475597}, {"micro_f1_no_misc": 0.6985131287567226, "micro_f1": 0.6126359399274987}, {"micro_f1_no_misc": 0.7417139444610331, "micro_f1": 0.6364508393285372}], "total": {"test_micro_f1_no_misc": 75.14683816033596, "test_micro_f1_no_misc_se": 2.0029983849753843, "test_micro_f1": 59.46938029478168, "test_micro_f1_se": 4.874372935154392}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "dansk", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.6715261958997722, "micro_f1": 0.5647231389805648}, {"micro_f1_no_misc": 0.6446194225721784, "micro_f1": 0.4356973193077706}, {"micro_f1_no_misc": 0.6033459255261737, "micro_f1": 0.5217391304347826}, {"micro_f1_no_misc": 0.6578483245149912, "micro_f1": 0.5468354430379746}, {"micro_f1_no_misc": 0.5771324863883847, "micro_f1": 0.45222929936305734}, {"micro_f1_no_misc": 0.6135148274185708, "micro_f1": 0.48963259367042566}, {"micro_f1_no_misc": 0.6200635497049478, "micro_f1": 0.5324580598103573}, {"micro_f1_no_misc": 0.6533066132264529, "micro_f1": 0.48347107438016534}, {"micro_f1_no_misc": 0.6594871794871795, "micro_f1": 0.4475831763967357}, {"micro_f1_no_misc": 0.6201089648340762, "micro_f1": 0.4563011456628478}], "total": {"test_micro_f1_no_misc": 63.20953489572727, "test_micro_f1_no_misc_se": 1.8543861620000914, "test_micro_f1": 49.30670381044682, "test_micro_f1_se": 2.8390152994294064}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb", "no"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.7564555080809958, "micro_f1": 0.6557926829268292}, {"micro_f1_no_misc": 0.8162281582647118, "micro_f1": 0.7288649376894578}, {"micro_f1_no_misc": 0.7899598393574296, "micro_f1": 0.5929814037192562}, {"micro_f1_no_misc": 0.8503634031637451, "micro_f1": 0.7635256180580438}, {"micro_f1_no_misc": 0.8075253256150507, "micro_f1": 0.6914646296911325}, {"micro_f1_no_misc": 0.7966379663796639, "micro_f1": 0.7397308781869687}, {"micro_f1_no_misc": 0.7683900798654897, "micro_f1": 0.6722483865341008}, {"micro_f1_no_misc": 0.8047464940668825, "micro_f1": 0.7451860160777714}, {"micro_f1_no_misc": 0.7855504587155964, "micro_f1": 0.7185075119696219}, {"micro_f1_no_misc": 0.8004056795131845, "micro_f1": 0.6643902439024391}], "total": {"test_micro_f1_no_misc": 79.76262913022751, "test_micro_f1_no_misc_se": 1.6055275583091353, "test_micro_f1": 69.72692308755622, "test_micro_f1_se": 3.2189707917014734}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.8192902638762511, "micro_f1": 0.7867105469362169}, {"micro_f1_no_misc": 0.7926509186351706, "micro_f1": 0.6418724870763929}, {"micro_f1_no_misc": 0.7795575896262396, "micro_f1": 0.7200126262626263}, {"micro_f1_no_misc": 0.7637296834901625, "micro_f1": 0.6777857656362329}, {"micro_f1_no_misc": 0.7940169399891871, "micro_f1": 0.736232790988736}, {"micro_f1_no_misc": 0.7657899445339058, "micro_f1": 0.5687515826791594}, {"micro_f1_no_misc": 0.7587555555555556, "micro_f1": 0.7057767135588147}, {"micro_f1_no_misc": 0.774493927125506, "micro_f1": 0.7159814209530363}, {"micro_f1_no_misc": 0.7844118698605649, "micro_f1": 0.6806987399770905}, {"micro_f1_no_misc": 0.7898966704936854, "micro_f1": 0.6988025790604852}], "total": {"test_micro_f1_no_misc": 78.22593363186228, "test_micro_f1_no_misc_se": 1.1154785582374085, "test_micro_f1": 69.32625253128792, "test_micro_f1_se": 3.6104738928992264}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.7647597254004577, "micro_f1": 0.6674791086350976}, {"micro_f1_no_misc": 0.7010166358595195, "micro_f1": 0.401934044135879}, {"micro_f1_no_misc": 0.7453593526891956, "micro_f1": 0.5565500406834826}, {"micro_f1_no_misc": 0.6925647451963242, "micro_f1": 0.502540937323546}, {"micro_f1_no_misc": 0.7271546123863144, "micro_f1": 0.6588390937655034}, {"micro_f1_no_misc": 0.7454667562122229, "micro_f1": 0.6969247869581326}, {"micro_f1_no_misc": 0.7375790424570913, "micro_f1": 0.7102177554438861}, {"micro_f1_no_misc": 0.7371810750557345, "micro_f1": 0.5793842960913178}, {"micro_f1_no_misc": 0.7568423433612306, "micro_f1": 0.6062992125984252}, {"micro_f1_no_misc": 0.7112757582773791, "micro_f1": 0.5436416628317225}], "total": {"test_micro_f1_no_misc": 73.1920004689547, "test_micro_f1_no_misc_se": 1.47198085999323, "test_micro_f1": 59.23810938466993, "test_micro_f1_se": 5.960555893646317}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "fone", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.7842331402951617, "micro_f1": 0.6934300552304015}, {"micro_f1_no_misc": 0.8325715884712248, "micro_f1": 0.8033269797262172}, {"micro_f1_no_misc": 0.7683777499552853, "micro_f1": 0.6802374893977947}, {"micro_f1_no_misc": 0.799848585218132, "micro_f1": 0.7649402390438248}, {"micro_f1_no_misc": 0.811509433962264, "micro_f1": 0.7741711508418676}, {"micro_f1_no_misc": 0.8130442838614045, "micro_f1": 0.7985257985257986}, {"micro_f1_no_misc": 0.8078126481463923, "micro_f1": 0.7962227517430058}, {"micro_f1_no_misc": 0.8104989904816845, "micro_f1": 0.7907309653753244}, {"micro_f1_no_misc": 0.79007259172062, "micro_f1": 0.7797246558197748}, {"micro_f1_no_misc": 0.8444191775630093, "micro_f1": 0.8251948750111996}], "total": {"test_micro_f1_no_misc": 80.6238818967518, "test_micro_f1_no_misc_se": 1.3806475673527192, "test_micro_f1": 77.06504960715209, "test_micro_f1_se": 2.932141550874833}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "germeval", "task": "named-entity-recognition", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.7198959687906371, "micro_f1": 0.6168070680090405}, {"micro_f1_no_misc": 0.7335692618806876, "micro_f1": 0.6521291915243776}, {"micro_f1_no_misc": 0.7142504322054829, "micro_f1": 0.626918536009445}, {"micro_f1_no_misc": 0.661021434241863, "micro_f1": 0.5673154906731548}, {"micro_f1_no_misc": 0.6944444444444444, "micro_f1": 0.5997026969632617}, {"micro_f1_no_misc": 0.6995316736504806, "micro_f1": 0.6127236580516898}, {"micro_f1_no_misc": 0.7288409703504042, "micro_f1": 0.6450624042040726}, {"micro_f1_no_misc": 0.7160096540627514, "micro_f1": 0.6099438319117952}, {"micro_f1_no_misc": 0.6995048214751107, "micro_f1": 0.5763178599527932}, {"micro_f1_no_misc": 0.7193268186753529, "micro_f1": 0.6038975257280491}], "total": {"test_micro_f1_no_misc": 70.86395479777215, "test_micro_f1_no_misc_se": 1.3053095887498618, "test_micro_f1": 61.1081826302768, "test_micro_f1_se": 1.6569775709701806}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "conll-nl", "task": "named-entity-recognition", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.7487875848690593, "micro_f1": 0.688293370944993}, {"micro_f1_no_misc": 0.7292753623188406, "micro_f1": 0.713869221157851}, {"micro_f1_no_misc": 0.7440000000000001, "micro_f1": 0.6450084602368866}, {"micro_f1_no_misc": 0.7017913593256059, "micro_f1": 0.5930987359070722}, {"micro_f1_no_misc": 0.6975633062589585, "micro_f1": 0.6447042153737158}, {"micro_f1_no_misc": 0.7376884422110553, "micro_f1": 0.5954650016431153}, {"micro_f1_no_misc": 0.7231869254341164, "micro_f1": 0.6783497626871121}, {"micro_f1_no_misc": 0.6788079470198676, "micro_f1": 0.6495201535508637}, {"micro_f1_no_misc": 0.7494199535962878, "micro_f1": 0.6290672451193059}, {"micro_f1_no_misc": 0.7275766016713092, "micro_f1": 0.682741116751269}], "total": {"test_micro_f1_no_misc": 72.380974827051, "test_micro_f1_no_misc_se": 1.478806205022256, "test_micro_f1": 65.20117283372186, "test_micro_f1_se": 2.4518782767725638}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "conll-en", "task": "named-entity-recognition", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"micro_f1_no_misc": 0.819975835682642, "micro_f1": 0.8000724375226368}, {"micro_f1_no_misc": 0.85301811839938, "micro_f1": 0.8194479615092428}, {"micro_f1_no_misc": 0.8383636554842782, "micro_f1": 0.7900355871886121}, {"micro_f1_no_misc": 0.8313694425190612, "micro_f1": 0.801058201058201}, {"micro_f1_no_misc": 0.8092825293879206, "micro_f1": 0.7742282842785356}, {"micro_f1_no_misc": 0.8438401318500207, "micro_f1": 0.8266345619559178}, {"micro_f1_no_misc": 0.7790536527420314, "micro_f1": 0.772472152663846}, {"micro_f1_no_misc": 0.8471633353523116, "micro_f1": 0.812175596023577}, {"micro_f1_no_misc": 0.8140400281605149, "micro_f1": 0.8015663418632182}, {"micro_f1_no_misc": 0.8515857047044171, "micro_f1": 0.832506099099857}], "total": {"test_micro_f1_no_misc": 82.87692434282577, "test_micro_f1_no_misc_se": 1.4489473274262044, "test_micro_f1": 80.30197223163646, "test_micro_f1_se": 1.2611464411822095}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.6753330947970577, "macro_f1": 0.8354094671702965}, {"mcc": 0.6008227579034925, "macro_f1": 0.7982243386834094}, {"mcc": 0.6259222589092767, "macro_f1": 0.8129454232577684}, {"mcc": 0.6337028494956432, "macro_f1": 0.8158125319216594}, {"mcc": 0.638931955433213, "macro_f1": 0.8190868008999821}, {"mcc": 0.6484562466162156, "macro_f1": 0.8241644184795259}, {"mcc": 0.640096788189425, "macro_f1": 0.809756126985276}, {"mcc": 0.6648149802650496, "macro_f1": 0.8324072914318161}, {"mcc": 0.6651002699146922, "macro_f1": 0.8265164562501028}, {"mcc": 0.6270756127139481, "macro_f1": 0.8134749615427531}], "total": {"test_mcc": 64.20256814238014, "test_mcc_se": 1.3806205170135917, "test_macro_f1": 81.87797816622589, "test_macro_f1_se": 0.6933150972888906}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.45815813412820916, "macro_f1": 0.6807408733205929}, {"mcc": 0.5594763792195514, "macro_f1": 0.777540024704531}, {"mcc": 0.5873384885338127, "macro_f1": 0.7927402570124686}, {"mcc": 0.5556457609071812, "macro_f1": 0.7642273302889597}, {"mcc": 0.5711139101003354, "macro_f1": 0.7811166518840669}, {"mcc": 0.5703903074278102, "macro_f1": 0.7844508420962946}, {"mcc": 0.5692169664033068, "macro_f1": 0.7813636606808922}, {"mcc": 0.5535986818175728, "macro_f1": 0.7474213836477988}, {"mcc": 0.5972454485191661, "macro_f1": 0.7860252376916915}, {"mcc": 0.5901166312212349, "macro_f1": 0.786269027648338}], "total": {"test_mcc": 56.123007082781804, "test_mcc_se": 2.4248177031145794, "test_macro_f1": 76.81895288975633, "test_macro_f1_se": 2.0695854824344844}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb", "no"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5778162769768153, "macro_f1": 0.7831650685917687}, {"mcc": 0.5682142964445092, "macro_f1": 0.769898115835486}, {"mcc": 0.5578232548644257, "macro_f1": 0.7471405826476636}, {"mcc": 0.5347595018400935, "macro_f1": 0.724102564102564}, {"mcc": 0.4728562825179466, "macro_f1": 0.7203764497774964}, {"mcc": 0.5253211660423984, "macro_f1": 0.7307177011302572}, {"mcc": 0.5631488370368376, "macro_f1": 0.7566730090230983}, {"mcc": 0.5739234814895051, "macro_f1": 0.7592448858130807}, {"mcc": 0.5512550672911027, "macro_f1": 0.7508312095416452}, {"mcc": 0.572582260360843, "macro_f1": 0.7785863313986316}], "total": {"test_mcc": 54.97700424864477, "test_mcc_se": 1.983317028843678, "test_macro_f1": 75.20735917861691, "test_macro_f1_se": 1.3593322487922632}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.39040717111509404, "macro_f1": 0.6763078868342026}, {"mcc": 0.44222967869117824, "macro_f1": 0.7209273244263287}, {"mcc": 0.4211157114573171, "macro_f1": 0.6605657577349292}, {"mcc": 0.44333620149287334, "macro_f1": 0.6956919273658118}, {"mcc": 0.4631499191698088, "macro_f1": 0.7254652118137135}, {"mcc": 0.4541321475680326, "macro_f1": 0.7261087144089733}, {"mcc": 0.46857665025348016, "macro_f1": 0.6978164531464024}, {"mcc": 0.466719276233895, "macro_f1": 0.7246444713990019}, {"mcc": 0.4746291042937628, "macro_f1": 0.7307267003926132}, {"mcc": 0.49260037300771964, "macro_f1": 0.7450096224091607}], "total": {"test_mcc": 45.16896233283162, "test_mcc_se": 1.8126731769553575, "test_macro_f1": 71.03264069931137, "test_macro_f1_se": 1.6552425741451702}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.24406697300198082, "macro_f1": 0.6214774387073436}, {"mcc": 0.2315433770346097, "macro_f1": 0.6141439256448726}, {"mcc": 0.1784498468982388, "macro_f1": 0.5624781510973005}, {"mcc": 0.21362745572641811, "macro_f1": 0.46513481412803764}, {"mcc": 0.21405451752100485, "macro_f1": 0.5493297106636507}, {"mcc": 0.2222985894010519, "macro_f1": 0.5919827090233397}, {"mcc": 0.22009913829349345, "macro_f1": 0.5549877479213354}, {"mcc": 0.13037181821996266, "macro_f1": 0.434442873705075}, {"mcc": 0.20383828505819265, "macro_f1": 0.5798495209302774}, {"mcc": 0.2364319788759912, "macro_f1": 0.6162636354370871}], "total": {"test_mcc": 20.947819800309436, "test_mcc_se": 2.0636931479183813, "test_macro_f1": 55.9009052725832, "test_macro_f1_se": 3.9304844279959728}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.13609229525458366, "macro_f1": 0.43295111051541885}, {"mcc": 0.10435216780625971, "macro_f1": 0.3986232963142377}, {"mcc": 0.15461291548520387, "macro_f1": 0.4826588016822328}, {"mcc": 0.13566870829070424, "macro_f1": 0.4036700351345212}, {"mcc": 0.16410111526758928, "macro_f1": 0.5258709281995633}, {"mcc": 0.15252006910224924, "macro_f1": 0.47203920695829565}, {"mcc": 0.14401227450129064, "macro_f1": 0.44020467516564254}, {"mcc": 0.10567010516947503, "macro_f1": 0.3625286470126639}, {"mcc": 0.1541286496907038, "macro_f1": 0.4691538389877413}, {"mcc": 0.10804791016226274, "macro_f1": 0.4384217105798844}], "total": {"test_mcc": 13.59206210730322, "test_mcc_se": 1.3866579227461908, "test_macro_f1": 44.26122250550201, "test_macro_f1_se": 2.9281972753598615}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-de", "task": "linguistic-acceptability", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.47025857371740176, "macro_f1": 0.7173594453389414}, {"mcc": 0.3759994539948283, "macro_f1": 0.6798761130468447}, {"mcc": 0.41884095651728986, "macro_f1": 0.7060883342326725}, {"mcc": 0.5293698290388682, "macro_f1": 0.7573110889219568}, {"mcc": 0.4583070801570533, "macro_f1": 0.7203121060876447}, {"mcc": 0.5444375538603877, "macro_f1": 0.771938672463963}, {"mcc": 0.4339178648529194, "macro_f1": 0.7059774737677359}, {"mcc": 0.4693944072551473, "macro_f1": 0.7346577413085726}, {"mcc": 0.35290722598045005, "macro_f1": 0.6662119464439191}, {"mcc": 0.41601979979130005, "macro_f1": 0.7000570625456168}], "total": {"test_mcc": 44.69452745165646, "test_mcc_se": 3.7682967979666215, "test_macro_f1": 71.59789984157868, "test_macro_f1_se": 2.007439923304539}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-nl", "task": "linguistic-acceptability", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5712133659192442, "macro_f1": 0.7780899477039294}, {"mcc": 0.5785708983380901, "macro_f1": 0.7807048902598701}, {"mcc": 0.6684261106322404, "macro_f1": 0.8328737705622128}, {"mcc": 0.6301703963344608, "macro_f1": 0.8121916295821867}, {"mcc": 0.6044577098848742, "macro_f1": 0.8010930698664124}, {"mcc": 0.573386875947868, "macro_f1": 0.7856383472061186}, {"mcc": 0.5831794894811566, "macro_f1": 0.7885197257691032}, {"mcc": 0.624777854691812, "macro_f1": 0.8114930556549127}, {"mcc": 0.5981550399195754, "macro_f1": 0.7873329552443866}, {"mcc": 0.5351653996435486, "macro_f1": 0.7493663001381352}], "total": {"test_mcc": 59.6750314079287, "test_mcc_se": 2.3197094786102044, "test_macro_f1": 79.27303691987268, "test_macro_f1_se": 1.4237213340860044}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-en", "task": "linguistic-acceptability", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5549493236311991, "macro_f1": 0.7697555138455303}, {"mcc": 0.602256045697812, "macro_f1": 0.7947378163462802}, {"mcc": 0.4693943426248024, "macro_f1": 0.7162546655573055}, {"mcc": 0.5323731554653467, "macro_f1": 0.7495247213640551}, {"mcc": 0.558716696962031, "macro_f1": 0.7787110416211981}, {"mcc": 0.5827975789850021, "macro_f1": 0.7909994802073448}, {"mcc": 0.5282701192328282, "macro_f1": 0.7384549943956045}, {"mcc": 0.5882575220032508, "macro_f1": 0.7917488979339304}, {"mcc": 0.4900805800226142, "macro_f1": 0.728939974755511}, {"mcc": 0.518032466236994, "macro_f1": 0.743849231647268}], "total": {"test_mcc": 54.2512783086188, "test_mcc_se": 2.6700744123963354, "test_macro_f1": 76.02976337674028, "test_macro_f1_se": 1.7692200258474584}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scandiqa-da", "task": "reading-comprehension", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"f1": 68.97372425554236, "em": 62.34848484848485}, {"f1": 69.67977183291812, "em": 63.83623957543594}, {"f1": 70.10283148241676, "em": 64.8018648018648}, {"f1": 69.98667235908702, "em": 63.62252663622527}, {"f1": 70.4712339831846, "em": 65.99845797995374}, {"f1": 70.25576795603732, "em": 64.50381679389314}, {"f1": 68.53857279832314, "em": 61.31045241809672}, {"f1": 67.82209782140406, "em": 59.905660377358494}, {"f1": 69.86700820679148, "em": 65.55727554179566}, {"f1": 71.00431886601757, "em": 64.2746913580247}], "total": {"test_f1": 69.67019995617225, "test_f1_se": 0.5941996992202709, "test_em": 63.61594703311333, "test_em_se": 1.1834234359946476}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "norquad", "task": "reading-comprehension", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"f1": 86.9398925292571, "em": 69.44444444444444}, {"f1": 72.5864547224422, "em": 45.9349593495935}, {"f1": 83.96635955553295, "em": 65.6119900083264}, {"f1": 77.87923952392515, "em": 55.19215044971382}, {"f1": 85.42499327594454, "em": 68.15550041356492}, {"f1": 74.35987578353561, "em": 48.39506172839506}, {"f1": 70.64595865830327, "em": 46.30252100840336}, {"f1": 82.09817240372664, "em": 61.064189189189186}, {"f1": 72.84037288526683, "em": 46.42857142857143}, {"f1": 74.15279043444814, "em": 46.854304635761586}], "total": {"test_f1": 78.08941097723824, "test_f1_se": 3.7270990699369944, "test_em": 55.33836926559637, "test_em_se": 6.09829160891163}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scandiqa-sv", "task": "reading-comprehension", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"f1": 63.66955266955253, "em": 50.68181818181818}, {"f1": 70.29387117265628, "em": 64.36694465504169}, {"f1": 67.55974994834168, "em": 61.46076146076146}, {"f1": 69.44977382124837, "em": 63.16590563165906}, {"f1": 68.95079547671497, "em": 62.837316885119506}, {"f1": 67.56192238634983, "em": 62.29007633587786}, {"f1": 69.92006273291305, "em": 63.41653666146646}, {"f1": 70.49392736892729, "em": 66.0377358490566}, {"f1": 70.58735854788483, "em": 65.015479876161}, {"f1": 68.91934610616521, "em": 63.81172839506173}], "total": {"test_f1": 68.74063602307541, "test_f1_se": 1.2962819292902061, "test_em": 62.30843039320236, "test_em_se": 2.6608647090735498}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "nqii", "task": "reading-comprehension", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"f1": 65.7654212916897, "em": 37.69230769230769}, {"f1": 66.06836782450797, "em": 34.42367601246106}, {"f1": 60.48076732760953, "em": 36.91588785046729}, {"f1": 60.26100356518067, "em": 36.62182361733931}, {"f1": 66.61949136594247, "em": 38.557993730407524}, {"f1": 66.06741128783396, "em": 40.98613251155624}, {"f1": 66.110276760877, "em": 41.23076923076923}, {"f1": 59.71597516459857, "em": 35.58282208588957}, {"f1": 64.13096652140368, "em": 36.44578313253012}, {"f1": 65.63748158602559, "em": 40.963855421686745}], "total": {"test_f1": 64.08571626956692, "test_f1_se": 1.7325906959047936, "test_em": 37.94210512854147, "test_em_se": 1.4988969095067297}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "foqa", "task": "reading-comprehension", "dataset_languages": ["fo"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"f1": 79.57604931773197, "em": 62.5}, {"f1": 75.47909298040821, "em": 57.98525798525799}, {"f1": 80.0901164971675, "em": 62.22222222222222}, {"f1": 77.26337106594559, "em": 60.43689320388349}, {"f1": 82.24565830958674, "em": 66.33663366336634}, {"f1": 78.61697470261439, "em": 62.22222222222222}, {"f1": 79.21417240316494, "em": 61.320754716981135}, {"f1": 81.18669351077749, "em": 60.81424936386768}, {"f1": 80.1986407790337, "em": 63.591022443890274}, {"f1": 80.08835079155939, "em": 61.42506142506142}], "total": {"test_f1": 79.39591203579899, "test_f1_se": 1.1957096232400337, "test_em": 61.885431724675286, "test_em_se": 1.343940807802668}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "germanquad", "task": "reading-comprehension", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"f1": 72.4202422737163, "em": 43.71212121212121}, {"f1": 64.67266038649366, "em": 36.01213040181956}, {"f1": 71.76732696923978, "em": 40.17094017094017}, {"f1": 73.13205367234461, "em": 41.70471841704718}, {"f1": 73.18466964540575, "em": 43.48496530454896}, {"f1": 73.85233790206088, "em": 43.66412213740458}, {"f1": 63.75359343264981, "em": 36.193447737909516}, {"f1": 72.17772639503896, "em": 44.0251572327044}, {"f1": 69.44378052707913, "em": 41.56346749226006}, {"f1": 58.99658993787653, "em": 34.41358024691358}], "total": {"test_f1": 69.34009811419052, "test_f1_se": 3.153264099584671, "test_em": 40.49446503536693, "test_em_se": 2.2640455559005477}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "squad", "task": "reading-comprehension", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"f1": 89.19954242670288, "em": 80.07575757575758}, {"f1": 88.02624633033028, "em": 76.95223654283548}, {"f1": 89.66664402169305, "em": 80.03108003108004}, {"f1": 88.23900021283498, "em": 78.23439878234399}, {"f1": 89.9649690079739, "em": 81.57286044718582}, {"f1": 84.25681698224409, "em": 72.13740458015268}, {"f1": 88.40587708531982, "em": 77.37909516380655}, {"f1": 88.33409538180767, "em": 78.22327044025157}, {"f1": 89.10740598285628, "em": 77.3219814241486}, {"f1": 85.66179570895187, "em": 73.8425925925926}], "total": {"test_f1": 88.08623931407149, "test_f1_se": 1.1134009150042512, "test_em": 77.57706775801549, "test_em_se": 1.7665698987154723}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "squad-nl", "task": "reading-comprehension", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"f1": 84.74923469023136, "em": 67.65151515151516}, {"f1": 83.56473927276564, "em": 67.47536012130402}, {"f1": 78.66477002979545, "em": 66.66666666666667}, {"f1": 82.14431452505224, "em": 70.01522070015221}, {"f1": 84.44844723024706, "em": 70.00771010023131}, {"f1": 83.82359195161197, "em": 67.48091603053435}, {"f1": 80.6835970750289, "em": 67.47269890795631}, {"f1": 84.7376664346417, "em": 73.11320754716981}, {"f1": 78.42882426094472, "em": 66.79566563467492}, {"f1": 84.80311314928873, "em": 69.29012345679013}], "total": {"test_f1": 82.60482986196078, "test_f1_se": 1.5550424401697795, "test_em": 68.59690843169949, "test_em_se": 1.248374689919994}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "nordjylland-news", "task": "summarization", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"bertscore": 0.6845955996832345, "rouge_l": 0.24835848515763065}, {"bertscore": 0.6833483557275031, "rouge_l": 0.24404253456992447}, {"bertscore": 0.6851947878894862, "rouge_l": 0.25449463969233393}, {"bertscore": 0.6821783548803069, "rouge_l": 0.246952120098328}, {"bertscore": 0.6915623839304317, "rouge_l": 0.2584479400315598}, {"bertscore": 0.6753648002340924, "rouge_l": 0.23234364056206436}, {"bertscore": 0.6796348437201232, "rouge_l": 0.23698839143950945}, {"bertscore": 0.680618575119297, "rouge_l": 0.23740214964479403}, {"bertscore": 0.6873038843041286, "rouge_l": 0.2533363421039295}, {"bertscore": 0.686175413953606, "rouge_l": 0.25311673299992204}], "total": {"test_bertscore": 68.3597699944221, "test_bertscore_se": 0.27856823386001794, "test_rouge_l": 24.65482976299996, "test_rouge_l_se": 0.5389515102641524}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mlsum", "task": "summarization", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"bertscore": 0.6934560803274508, "rouge_l": 0.27266018900158917}, {"bertscore": 0.7098815155331977, "rouge_l": 0.320545701635881}, {"bertscore": 0.6946163635730045, "rouge_l": 0.27854372859660764}, {"bertscore": 0.6766621165443212, "rouge_l": 0.24499554971808427}, {"bertscore": 0.7292893283156445, "rouge_l": 0.3690936964848286}, {"bertscore": 0.6919338290899759, "rouge_l": 0.27330346150914564}, {"bertscore": 0.7270601665368304, "rouge_l": 0.366912870204814}, {"bertscore": 0.6911111713270657, "rouge_l": 0.26625624255023583}, {"bertscore": 0.7215813874354353, "rouge_l": 0.3480745092299396}, {"bertscore": 0.6870806619990617, "rouge_l": 0.2892554062315191}], "total": {"test_bertscore": 70.22672620681988, "test_bertscore_se": 1.1371679358927882, "test_rouge_l": 30.296413551626443, "test_rouge_l_se": 2.7793028390095573}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "rrn", "task": "summarization", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"bertscore": 0.6957781819510274, "rouge_l": 0.2350737208517433}, {"bertscore": 0.6856283298402559, "rouge_l": 0.21263373987238393}, {"bertscore": 0.6961424347828142, "rouge_l": 0.23184009054591975}, {"bertscore": 0.6849081834079698, "rouge_l": 0.2119851921423767}, {"bertscore": 0.6876701442524791, "rouge_l": 0.21174137530009493}, {"bertscore": 0.6871314455347601, "rouge_l": 0.2174837590321563}, {"bertscore": 0.6880497995880432, "rouge_l": 0.21883981156198307}, {"bertscore": 0.6859417023952119, "rouge_l": 0.20899805840492025}, {"bertscore": 0.6777118527388666, "rouge_l": 0.20329215817688295}, {"bertscore": 0.6832799384137616, "rouge_l": 0.20439181367580764}], "total": {"test_bertscore": 68.7224201290519, "test_bertscore_se": 0.3389736672447603, "test_rouge_l": 21.56279719564269, "test_rouge_l_se": 0.6580367401011722}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "no-sammendrag", "task": "summarization", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"bertscore": 0.6669961014558794, "rouge_l": 0.21670868076216337}, {"bertscore": 0.6602599475590978, "rouge_l": 0.1976979198431293}, {"bertscore": 0.6738115692714928, "rouge_l": 0.22554190922424075}, {"bertscore": 0.6718301473447355, "rouge_l": 0.2267984878866487}, {"bertscore": 0.6764863429852994, "rouge_l": 0.2295493756297118}, {"bertscore": 0.6739283366623567, "rouge_l": 0.22732297596803563}, {"bertscore": 0.6527854421292432, "rouge_l": 0.19547490177824112}, {"bertscore": 0.6505210642935708, "rouge_l": 0.17993726157460851}, {"bertscore": 0.6774845223699231, "rouge_l": 0.23186696018657627}, {"bertscore": 0.6507264144311193, "rouge_l": 0.18520254525708724}], "total": {"test_bertscore": 66.54829888502718, "test_bertscore_se": 0.6784920044593651, "test_rouge_l": 21.161010181104427, "test_rouge_l_se": 1.2368984668805878}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "wiki-lingua-nl", "task": "summarization", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"bertscore": 0.6802741323626833, "rouge_l": 0.21646066553505616}, {"bertscore": 0.6919419290134101, "rouge_l": 0.23839427267837626}, {"bertscore": 0.6529832454834832, "rouge_l": 0.17588300466485485}, {"bertscore": 0.7118755530973431, "rouge_l": 0.2647712430391659}, {"bertscore": 0.6757536622535554, "rouge_l": 0.23711234690370736}, {"bertscore": 0.711589095837553, "rouge_l": 0.26669513916003595}, {"bertscore": 0.720926507783588, "rouge_l": 0.28998539332969375}, {"bertscore": 0.687643855373608, "rouge_l": 0.2370560177761582}, {"bertscore": 0.6976123953936622, "rouge_l": 0.24921586153428804}, {"bertscore": 0.7156576657580445, "rouge_l": 0.282873438112729}], "total": {"test_bertscore": 69.4625804235693, "test_bertscore_se": 1.3197454223398934, "test_rouge_l": 24.584473827340652, "test_rouge_l_se": 2.075391454940532}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "swedn", "task": "summarization", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"bertscore": 0.6455711482849438, "rouge_l": 0.18294171743531173}, {"bertscore": 0.6662508859590162, "rouge_l": 0.2156371899647058}, {"bertscore": 0.6650642680178862, "rouge_l": 0.2150179012112317}, {"bertscore": 0.6625737126887543, "rouge_l": 0.20547326941984817}, {"bertscore": 0.6560453792772023, "rouge_l": 0.1891230786542502}, {"bertscore": 0.6591811891266843, "rouge_l": 0.19784789717163864}, {"bertscore": 0.6645043829485076, "rouge_l": 0.2069959878991525}, {"bertscore": 0.6604005918488838, "rouge_l": 0.2078397314924611}, {"bertscore": 0.6633424384635873, "rouge_l": 0.19682828304476985}, {"bertscore": 0.666611108725192, "rouge_l": 0.21023126936184947}], "total": {"test_bertscore": 66.09545105340658, "test_bertscore_se": 0.3931217528697877, "test_rouge_l": 20.27936325655219, "test_rouge_l_se": 0.672977664083486}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "cnn-dailymail", "task": "summarization", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"bertscore": 0.6919370137475198, "rouge_l": 0.2201447251345794}, {"bertscore": 0.6941697885922622, "rouge_l": 0.22816232571962283}, {"bertscore": 0.6906706179579487, "rouge_l": 0.2198143849479029}, {"bertscore": 0.6912080070032971, "rouge_l": 0.19939026629603673}, {"bertscore": 0.6861438419000478, "rouge_l": 0.21624931957294763}, {"bertscore": 0.7030286003428046, "rouge_l": 0.260336162628569}, {"bertscore": 0.6835224525420927, "rouge_l": 0.20759403416409822}, {"bertscore": 0.6851279340189649, "rouge_l": 0.21605495751954185}, {"bertscore": 0.675458670280932, "rouge_l": 0.20826649566557487}, {"bertscore": 0.6970411080110352, "rouge_l": 0.23945382040205687}], "total": {"test_bertscore": 68.98308034396905, "test_bertscore_se": 0.47746974767988754, "test_rouge_l": 22.154664920509298, "test_rouge_l_se": 1.092100959630449}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "danske-talemaader", "task": "knowledge", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.8077437633565784, "accuracy": 0.8564356435643564}, {"mcc": 0.8499059763970528, "accuracy": 0.8873762376237624}, {"mcc": 0.8283202941369843, "accuracy": 0.8712871287128713}, {"mcc": 0.8739427015625485, "accuracy": 0.905940594059406}, {"mcc": 0.8640084443534234, "accuracy": 0.8985148514851485}, {"mcc": 0.8015799725261633, "accuracy": 0.8514851485148515}, {"mcc": 0.8629247100574107, "accuracy": 0.8972772277227723}, {"mcc": 0.8149357557901629, "accuracy": 0.8613861386138614}, {"mcc": 0.8493375632558018, "accuracy": 0.8873762376237624}, {"mcc": 0.8642435772184001, "accuracy": 0.8985148514851485}], "total": {"test_mcc": 84.16942758654524, "test_mcc_se": 1.6371982822169222, "test_accuracy": 88.1559405940594, "test_accuracy_se": 1.2278986552925226}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "danish-citizen-tests", "task": "knowledge", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.9157757845122756, "accuracy": 0.943359375}, {"mcc": 0.8912932590525463, "accuracy": 0.927734375}, {"mcc": 0.9260717989079011, "accuracy": 0.951171875}, {"mcc": 0.9180757038353516, "accuracy": 0.9453125}, {"mcc": 0.921560300316056, "accuracy": 0.947265625}, {"mcc": 0.8798928947561444, "accuracy": 0.919921875}, {"mcc": 0.8881015488650251, "accuracy": 0.92578125}, {"mcc": 0.9090383242084118, "accuracy": 0.939453125}, {"mcc": 0.8764454237876692, "accuracy": 0.91796875}, {"mcc": 0.9002037491988851, "accuracy": 0.93359375}], "total": {"test_mcc": 90.26458787440265, "test_mcc_se": 1.114199039373682, "test_accuracy": 93.515625, "test_accuracy_se": 0.7348050233286566}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu-no", "task": "knowledge", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5875415769346567, "accuracy": 0.689453125}, {"mcc": 0.5822119342821356, "accuracy": 0.68408203125}, {"mcc": 0.619312510845959, "accuracy": 0.71337890625}, {"mcc": 0.6042899936415229, "accuracy": 0.7021484375}, {"mcc": 0.5853101481524113, "accuracy": 0.6875}, {"mcc": 0.5981006319002382, "accuracy": 0.6953125}, {"mcc": 0.5680369592738552, "accuracy": 0.673828125}, {"mcc": 0.6066277496034819, "accuracy": 0.703125}, {"mcc": 0.6208705414429093, "accuracy": 0.7138671875}, {"mcc": 0.6154034723977138, "accuracy": 0.71044921875}], "total": {"test_mcc": 59.87705518474884, "test_mcc_se": 1.0943475946407835, "test_accuracy": 69.7314453125, "test_accuracy_se": 0.8393612071633796}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu-sv", "task": "knowledge", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.6134466696103187, "accuracy": 0.70947265625}, {"mcc": 0.6244220204433931, "accuracy": 0.71728515625}, {"mcc": 0.6281057668601381, "accuracy": 0.7197265625}, {"mcc": 0.6290889973244437, "accuracy": 0.720703125}, {"mcc": 0.6335281303035633, "accuracy": 0.72509765625}, {"mcc": 0.6251734148330245, "accuracy": 0.7177734375}, {"mcc": 0.6008622830580181, "accuracy": 0.7001953125}, {"mcc": 0.6274556816369166, "accuracy": 0.72021484375}, {"mcc": 0.6092583579119107, "accuracy": 0.705078125}, {"mcc": 0.6206552209715368, "accuracy": 0.7138671875}], "total": {"test_mcc": 62.11996542953264, "test_mcc_se": 0.6347254034786592, "test_accuracy": 71.494140625, "test_accuracy_se": 0.4829189760615348}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu-de", "task": "knowledge", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.6249351461564074, "accuracy": 0.71875}, {"mcc": 0.6283629032565241, "accuracy": 0.72119140625}, {"mcc": 0.6127719428945105, "accuracy": 0.7080078125}, {"mcc": 0.6396805189710807, "accuracy": 0.73046875}, {"mcc": 0.6138612241010676, "accuracy": 0.7109375}, {"mcc": 0.6192878505735552, "accuracy": 0.71435546875}, {"mcc": 0.5923836558214476, "accuracy": 0.693359375}, {"mcc": 0.6398128353804986, "accuracy": 0.72998046875}, {"mcc": 0.6200247692105167, "accuracy": 0.71484375}, {"mcc": 0.6147907170774427, "accuracy": 0.7099609375}], "total": {"test_mcc": 62.059115634430505, "test_mcc_se": 0.8645026244669363, "test_accuracy": 71.5185546875, "test_accuracy_se": 0.677482294943782}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu-nl", "task": "knowledge", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.6090497802858441, "accuracy": 0.7060546875}, {"mcc": 0.6171621451567462, "accuracy": 0.7109375}, {"mcc": 0.6219960231219458, "accuracy": 0.71533203125}, {"mcc": 0.6454818977807671, "accuracy": 0.73291015625}, {"mcc": 0.5969508881542287, "accuracy": 0.6962890625}, {"mcc": 0.6323122825234341, "accuracy": 0.72314453125}, {"mcc": 0.6539804272748738, "accuracy": 0.73876953125}, {"mcc": 0.6380817928544548, "accuracy": 0.72705078125}, {"mcc": 0.5795232533343917, "accuracy": 0.68310546875}, {"mcc": 0.6079493544041736, "accuracy": 0.7041015625}], "total": {"test_mcc": 62.024878448908595, "test_mcc_se": 1.4207127484857989, "test_accuracy": 71.376953125, "test_accuracy_se": 1.0665449072962252}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu", "task": "knowledge", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.6914502074218439, "accuracy": 0.76708984375}, {"mcc": 0.6405383060049541, "accuracy": 0.7294921875}, {"mcc": 0.6766193018586725, "accuracy": 0.755859375}, {"mcc": 0.6774397676229124, "accuracy": 0.7568359375}, {"mcc": 0.6733839084057511, "accuracy": 0.75341796875}, {"mcc": 0.6636813360681668, "accuracy": 0.74658203125}, {"mcc": 0.718354364711627, "accuracy": 0.7880859375}, {"mcc": 0.7092943433019087, "accuracy": 0.78125}, {"mcc": 0.7065830389765928, "accuracy": 0.77978515625}, {"mcc": 0.7085019511250171, "accuracy": 0.78125}], "total": {"test_mcc": 68.65846525497446, "test_mcc_se": 1.5225675687507667, "test_accuracy": 76.396484375, "test_accuracy_se": 1.160970029721745}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "arc-is", "task": "knowledge", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.7399708547261552, "accuracy": 0.8046875}, {"mcc": 0.7675112640991156, "accuracy": 0.826171875}, {"mcc": 0.7144139731551906, "accuracy": 0.78515625}, {"mcc": 0.7172126595995644, "accuracy": 0.7880859375}, {"mcc": 0.7003959930366657, "accuracy": 0.775390625}, {"mcc": 0.7242789217296391, "accuracy": 0.79296875}, {"mcc": 0.7260958274740934, "accuracy": 0.7939453125}, {"mcc": 0.6846257962873296, "accuracy": 0.763671875}, {"mcc": 0.7110624704462486, "accuracy": 0.783203125}, {"mcc": 0.7210275889109498, "accuracy": 0.7900390625}], "total": {"test_mcc": 72.06595349464952, "test_mcc_se": 1.3801940582000074, "test_accuracy": 79.033203125, "test_accuracy_se": 1.0386422647099836}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-da", "task": "common-sense-reasoning", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.48771664816783106, "accuracy": 0.5986328125}, {"mcc": 0.4771378831868259, "accuracy": 0.5986328125}, {"mcc": 0.5513004094278113, "accuracy": 0.6376953125}, {"mcc": 0.6176201256827105, "accuracy": 0.7060546875}, {"mcc": 0.5148289434075959, "accuracy": 0.6162109375}, {"mcc": 0.6068384878643447, "accuracy": 0.6904296875}, {"mcc": 0.4464614026943212, "accuracy": 0.55810546875}, {"mcc": 0.5646290892962887, "accuracy": 0.6640625}, {"mcc": 0.6983365541055792, "accuracy": 0.77197265625}, {"mcc": 0.6374744449560585, "accuracy": 0.72509765625}], "total": {"test_mcc": 56.023439887893666, "test_mcc_se": 4.965858867242933, "test_accuracy": 65.6689453125, "test_accuracy_se": 4.135080159650773}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-no", "task": "common-sense-reasoning", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.520015327504502, "accuracy": 0.62939453125}, {"mcc": 0.5319371533720467, "accuracy": 0.6376953125}, {"mcc": 0.7166981155194448, "accuracy": 0.78564453125}, {"mcc": 0.5612180513482142, "accuracy": 0.65771484375}, {"mcc": 0.5755710527873054, "accuracy": 0.6650390625}, {"mcc": 0.6012423935466513, "accuracy": 0.6943359375}, {"mcc": 0.5226950253743121, "accuracy": 0.62646484375}, {"mcc": 0.5644612048340011, "accuracy": 0.6552734375}, {"mcc": 0.6472765280102901, "accuracy": 0.73291015625}, {"mcc": 0.5613019298572529, "accuracy": 0.6640625}], "total": {"test_mcc": 58.0241678215402, "test_mcc_se": 3.799382953280359, "test_accuracy": 67.4853515625, "test_accuracy_se": 3.1130072129770503}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-sv", "task": "common-sense-reasoning", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5533984708590163, "accuracy": 0.6513671875}, {"mcc": 0.5866843524992038, "accuracy": 0.6865234375}, {"mcc": 0.5919044438156771, "accuracy": 0.67919921875}, {"mcc": 0.6192237494312293, "accuracy": 0.70947265625}, {"mcc": 0.6210679363944083, "accuracy": 0.708984375}, {"mcc": 0.42801445080844824, "accuracy": 0.5400390625}, {"mcc": 0.5779830232972236, "accuracy": 0.67333984375}, {"mcc": 0.46413248170885174, "accuracy": 0.5830078125}, {"mcc": 0.5751042024373184, "accuracy": 0.67578125}, {"mcc": 0.5270660969796526, "accuracy": 0.6357421875}], "total": {"test_mcc": 55.445792082310284, "test_mcc_se": 3.9713887395738063, "test_accuracy": 65.4345703125, "test_accuracy_se": 3.3953095570037686}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "winogrande-is", "task": "common-sense-reasoning", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5160761933340711, "accuracy": 0.7611607142857143}, {"mcc": 0.4237296405137389, "accuracy": 0.7120535714285714}, {"mcc": 0.506929551114637, "accuracy": 0.7578125}, {"mcc": 0.5136487440864977, "accuracy": 0.7589285714285714}, {"mcc": 0.46623463075836036, "accuracy": 0.7366071428571429}, {"mcc": 0.39566665127730394, "accuracy": 0.6941964285714286}, {"mcc": 0.4738448795752807, "accuracy": 0.7410714285714286}, {"mcc": 0.4402380766816769, "accuracy": 0.7209821428571429}, {"mcc": 0.4519686302294696, "accuracy": 0.7299107142857143}, {"mcc": 0.4397143243825288, "accuracy": 0.7131696428571429}], "total": {"test_mcc": 46.28051321953565, "test_mcc_se": 2.504733574889811, "test_accuracy": 73.25892857142857, "test_accuracy_se": 1.4087077288344008}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-de", "task": "common-sense-reasoning", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.5430347154567329, "accuracy": 0.6494140625}, {"mcc": 0.6165750541961293, "accuracy": 0.70703125}, {"mcc": 0.5698794486661225, "accuracy": 0.65771484375}, {"mcc": 0.6026803701566371, "accuracy": 0.7001953125}, {"mcc": 0.5958959325068939, "accuracy": 0.68505859375}, {"mcc": 0.5169283107979885, "accuracy": 0.6220703125}, {"mcc": 0.518323575886456, "accuracy": 0.62744140625}, {"mcc": 0.5589927003351027, "accuracy": 0.65625}, {"mcc": 0.6288902759505091, "accuracy": 0.71484375}, {"mcc": 0.4918388611143079, "accuracy": 0.6083984375}], "total": {"test_mcc": 56.4303924506688, "test_mcc_se": 2.8847441767007043, "test_accuracy": 66.2841796875, "test_accuracy_se": 2.3260322466971446}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-nl", "task": "common-sense-reasoning", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.592816804284686, "accuracy": 0.68310546875}, {"mcc": 0.67203641234761, "accuracy": 0.7529296875}, {"mcc": 0.6372533500333848, "accuracy": 0.71923828125}, {"mcc": 0.5699314129759327, "accuracy": 0.66455078125}, {"mcc": 0.543253629878563, "accuracy": 0.64306640625}, {"mcc": 0.4797833296210562, "accuracy": 0.58056640625}, {"mcc": 0.6298389302297951, "accuracy": 0.7158203125}, {"mcc": 0.6396588475118927, "accuracy": 0.72314453125}, {"mcc": 0.5665921528274201, "accuracy": 0.66943359375}, {"mcc": 0.6378824055106911, "accuracy": 0.72216796875}], "total": {"test_mcc": 59.69047275221031, "test_mcc_se": 3.585812908614111, "test_accuracy": 68.740234375, "test_accuracy_se": 3.1226476036378155}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag", "task": "common-sense-reasoning", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"mcc": 0.6432714321526674, "accuracy": 0.7255859375}, {"mcc": 0.6996832123176787, "accuracy": 0.77099609375}, {"mcc": 0.5852654987784135, "accuracy": 0.67138671875}, {"mcc": 0.6187124815213656, "accuracy": 0.70068359375}, {"mcc": 0.7098134108741703, "accuracy": 0.77685546875}, {"mcc": 0.7131477824052683, "accuracy": 0.779296875}, {"mcc": 0.7132425499149162, "accuracy": 0.7783203125}, {"mcc": 0.7052341689982298, "accuracy": 0.76953125}, {"mcc": 0.7649714729035594, "accuracy": 0.82080078125}, {"mcc": 0.6017579553074822, "accuracy": 0.6904296875}], "total": {"test_mcc": 67.55099965173751, "test_mcc_se": 3.6573256289249336, "test_accuracy": 74.8388671875, "test_accuracy_se": 2.9902032621904953}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "meta-llama/Meta-Llama-3-70B", "results": {"raw": [{"test_speed": 244.24, "test_speed_short": 28.24}, {"test_speed": 475.17, "test_speed_short": 52.949999999999996}, {"test_speed": 717.4, "test_speed_short": 101.78999999999999}, {"test_speed": 949.78, "test_speed_short": 126.35999999999999}, {"test_speed": 1175.8500000000001, "test_speed_short": 151.79}, {"test_speed": 1431.3999999999999, "test_speed_short": 200.07}, {"test_speed": 1654.67, "test_speed_short": 221.44}, {"test_speed": 1884.96, "test_speed_short": 244.95000000000002}, {"test_speed": 2107.54, "test_speed_short": 267.54}, {"test_speed": 2348.35, "test_speed_short": 292.4}], "total": {"test_speed": 1298.9360000000001, "test_speed_se": 438.6998802513736, "test_speed_short": 168.753, "test_speed_short_se": 56.32828447345831}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.8263452006713464, "macro_f1": 0.8139933324669121}, {"mcc": 0.8138376909191951, "macro_f1": 0.7950255819290444}, {"mcc": 0.815067230863739, "macro_f1": 0.8026049024488588}, {"mcc": 0.7957332017607683, "macro_f1": 0.7890706978245344}, {"mcc": 0.8153092627301636, "macro_f1": 0.8267516271962929}, {"mcc": 0.8139563317161289, "macro_f1": 0.8040459620837398}, {"mcc": 0.8106054627009983, "macro_f1": 0.778789809248079}, {"mcc": 0.8167737084823457, "macro_f1": 0.8165844177704127}, {"mcc": 0.818277336399166, "macro_f1": 0.7990988626435239}, {"mcc": 0.7951523775221864, "macro_f1": 0.7943732611812847}], "total": {"test_mcc": 81.21057803766037, "test_mcc_se": 0.6008626221092607, "test_macro_f1": 80.20338454792683, "test_macro_f1_se": 0.8752801022686576}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.5679959633763173, "macro_f1": 0.6976046629582942}, {"mcc": 0.6018073223782261, "macro_f1": 0.7185109505464334}, {"mcc": 0.5733227337487667, "macro_f1": 0.6948668778525162}, {"mcc": 0.5641738142620316, "macro_f1": 0.6910167446848977}, {"mcc": 0.6027647736544227, "macro_f1": 0.7284006914977131}, {"mcc": 0.6052121780919267, "macro_f1": 0.7226301157206573}, {"mcc": 0.5681297797190311, "macro_f1": 0.6867341914804782}, {"mcc": 0.6136096899156446, "macro_f1": 0.737708167162217}, {"mcc": 0.5637231975797988, "macro_f1": 0.6755160328614594}, {"mcc": 0.5529545976948453, "macro_f1": 0.6927727486421228}], "total": {"test_mcc": 58.13694050421011, "test_mcc_se": 1.3574166051282543, "test_macro_f1": 70.4576118340679, "test_macro_f1_se": 1.2759817321895845}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.38453951768886147, "macro_f1": 0.39782373877235955}, {"mcc": 0.4050231562688625, "macro_f1": 0.406056373605147}, {"mcc": 0.38863453834723716, "macro_f1": 0.40532158499467413}, {"mcc": 0.3809891911240034, "macro_f1": 0.4009781632493146}, {"mcc": 0.3815218200525575, "macro_f1": 0.3960371828909177}, {"mcc": 0.38769953654748085, "macro_f1": 0.3980685979575365}, {"mcc": 0.3796919367747782, "macro_f1": 0.3896719501416175}, {"mcc": 0.3984471669138772, "macro_f1": 0.3989523475372445}, {"mcc": 0.361284172065886, "macro_f1": 0.3889846611721612}, {"mcc": 0.38818770089124416, "macro_f1": 0.4042025490395309}], "total": {"test_mcc": 38.560187366747876, "test_mcc_se": 0.7239339493465917, "test_macro_f1": 39.860971493605035, "test_macro_f1_se": 0.3681708399054207}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hotter-and-colder-sentiment", "task": "sentiment-classification", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.5137077240337664, "macro_f1": 0.6307903883968793}, {"mcc": 0.46660886104616156, "macro_f1": 0.5990090350532312}, {"mcc": 0.5070182468720347, "macro_f1": 0.6305796755890811}, {"mcc": 0.4642229192460725, "macro_f1": 0.5796863107151013}, {"mcc": 0.43906928771236103, "macro_f1": 0.5501768873139691}, {"mcc": 0.49660052510295194, "macro_f1": 0.6208409367764774}, {"mcc": 0.5075500860160801, "macro_f1": 0.6464115397777652}, {"mcc": 0.5015115218189293, "macro_f1": 0.6519320371844223}, {"mcc": 0.44375997925802224, "macro_f1": 0.5520497342595808}, {"mcc": 0.5000241183428338, "macro_f1": 0.6327615001881557}], "total": {"test_mcc": 48.400732694492135, "test_mcc_se": 1.731124547714101, "test_macro_f1": 60.94238045254663, "test_macro_f1_se": 2.314396815223391}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "sb10k", "task": "sentiment-classification", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.5044341590082984, "macro_f1": 0.627227228511515}, {"mcc": 0.5695862646260024, "macro_f1": 0.6851495219626891}, {"mcc": 0.5600723434634294, "macro_f1": 0.6819371556648424}, {"mcc": 0.5360139880364378, "macro_f1": 0.6534556782641161}, {"mcc": 0.552908402725393, "macro_f1": 0.6842095032348494}, {"mcc": 0.6168920445445901, "macro_f1": 0.7223969432093682}, {"mcc": 0.5827530858415695, "macro_f1": 0.712880279267484}, {"mcc": 0.571775323048404, "macro_f1": 0.6916565549124192}, {"mcc": 0.5956630888120571, "macro_f1": 0.7042618053737123}, {"mcc": 0.6108514235042891, "macro_f1": 0.7257040632802516}], "total": {"test_mcc": 57.00950123610471, "test_mcc_se": 2.120746590157494, "test_macro_f1": 68.88878733681247, "test_macro_f1_se": 1.8979978777305233}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "dutch-social", "task": "sentiment-classification", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.10756302960525936, "macro_f1": 0.21883667106597046}, {"mcc": 0.11422236419737762, "macro_f1": 0.21108361545027007}, {"mcc": 0.0867271606041376, "macro_f1": 0.20109779179810724}, {"mcc": 0.13893257148353663, "macro_f1": 0.22952771284544174}, {"mcc": 0.09980543785650521, "macro_f1": 0.21683197760867665}, {"mcc": 0.08521217693767344, "macro_f1": 0.20170486960382217}, {"mcc": 0.09086594122712087, "macro_f1": 0.20257169450151905}, {"mcc": 0.13457386064250915, "macro_f1": 0.22867084203201116}, {"mcc": 0.0681361337169202, "macro_f1": 0.1968807886656614}, {"mcc": 0.13460333130229504, "macro_f1": 0.23695218639038865}], "total": {"test_mcc": 10.606420075733352, "test_mcc_se": 1.5032119712901226, "test_macro_f1": 21.441581499618685, "test_macro_f1_se": 0.8673961159694604}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "sst5", "task": "sentiment-classification", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6792550587668523, "macro_f1": 0.7171397730403942}, {"mcc": 0.7008731773391346, "macro_f1": 0.7249664726751841}, {"mcc": 0.6936796095800105, "macro_f1": 0.723333781249587}, {"mcc": 0.7152641982894267, "macro_f1": 0.7270323581189283}, {"mcc": 0.7138465875069272, "macro_f1": 0.7356808111256258}, {"mcc": 0.670859440273429, "macro_f1": 0.7046416486082459}, {"mcc": 0.6783205828677509, "macro_f1": 0.7055236879147939}, {"mcc": 0.6923622739208789, "macro_f1": 0.7184668924460063}, {"mcc": 0.7199404314571277, "macro_f1": 0.7332907917798935}, {"mcc": 0.708174034055773, "macro_f1": 0.7316804380264929}], "total": {"test_mcc": 69.72575394057311, "test_mcc_se": 1.0660580443241272, "test_macro_f1": 72.21756654985153, "test_macro_f1_se": 0.6703716749015108}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "fosent", "task": "sentiment-classification", "dataset_languages": ["fo"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.5381014771419368, "macro_f1": 0.5158579984376356}, {"mcc": 0.510835900945816, "macro_f1": 0.49765274663677134}, {"mcc": 0.5066213909185435, "macro_f1": 0.5011409705532494}, {"mcc": 0.5223833154784259, "macro_f1": 0.5097778973485187}, {"mcc": 0.46849066621842117, "macro_f1": 0.4657891128479364}, {"mcc": 0.5229365317116735, "macro_f1": 0.502686700684476}, {"mcc": 0.4755695620167231, "macro_f1": 0.4862914862914863}, {"mcc": 0.4956791477092226, "macro_f1": 0.4903553561297643}, {"mcc": 0.4517655314799829, "macro_f1": 0.47131642512077293}, {"mcc": 0.4937374907156545, "macro_f1": 0.49656923790686885}], "total": {"test_mcc": 49.86121014336399, "test_mcc_se": 1.67780197229251, "test_macro_f1": 49.37437931957479, "test_macro_f1_se": 0.9812094072985502}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.6488771466314399, "micro_f1": 0.37776431384428966}, {"micro_f1_no_misc": 0.664762992575671, "micro_f1": 0.4824081313526193}, {"micro_f1_no_misc": 0.6780962128966223, "micro_f1": 0.4789857589440778}, {"micro_f1_no_misc": 0.695562435500516, "micro_f1": 0.47648366683769444}, {"micro_f1_no_misc": 0.7037730800107038, "micro_f1": 0.507036967536123}, {"micro_f1_no_misc": 0.6653386454183268, "micro_f1": 0.5063446582071224}, {"micro_f1_no_misc": 0.6686583378598588, "micro_f1": 0.4759319580166485}, {"micro_f1_no_misc": 0.6027689030883919, "micro_f1": 0.4043272481406356}, {"micro_f1_no_misc": 0.5903155603917302, "micro_f1": 0.45035666088297666}, {"micro_f1_no_misc": 0.6600695373094411, "micro_f1": 0.4528433945756781}], "total": {"test_micro_f1_no_misc": 65.78222851682702, "test_micro_f1_no_misc_se": 2.248265545847685, "test_micro_f1": 46.12482758337866, "test_micro_f1_se": 2.5919486464837798}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "dansk", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.6526410026857655, "micro_f1": 0.4950684059815464}, {"micro_f1_no_misc": 0.6543589743589744, "micro_f1": 0.45733113673805603}, {"micro_f1_no_misc": 0.6291358024691359, "micro_f1": 0.4946846208362864}, {"micro_f1_no_misc": 0.6578073089700996, "micro_f1": 0.5084951456310679}, {"micro_f1_no_misc": 0.6149708650829224, "micro_f1": 0.4426713947990544}, {"micro_f1_no_misc": 0.5951174573929066, "micro_f1": 0.43369829683698297}, {"micro_f1_no_misc": 0.6445264452644527, "micro_f1": 0.51342383107089}, {"micro_f1_no_misc": 0.669452181987001, "micro_f1": 0.48375}, {"micro_f1_no_misc": 0.6641544983513895, "micro_f1": 0.49018977163074945}, {"micro_f1_no_misc": 0.6198723792160438, "micro_f1": 0.4347315928424758}], "total": {"test_micro_f1_no_misc": 64.0203691577869, "test_micro_f1_no_misc_se": 1.5066484426328934, "test_micro_f1": 47.540441963671086, "test_micro_f1_se": 1.8911601633086588}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb", "no"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.7644077341843439, "micro_f1": 0.655590480466996}, {"micro_f1_no_misc": 0.7805354700019543, "micro_f1": 0.606581678031426}, {"micro_f1_no_misc": 0.7715386174741536, "micro_f1": 0.6152216674232107}, {"micro_f1_no_misc": 0.7691685211410075, "micro_f1": 0.6393081761006288}, {"micro_f1_no_misc": 0.774613506916192, "micro_f1": 0.6123193916349811}, {"micro_f1_no_misc": 0.7471400394477317, "micro_f1": 0.6358814352574103}, {"micro_f1_no_misc": 0.7373716202054077, "micro_f1": 0.6033909047694502}, {"micro_f1_no_misc": 0.7197387221882018, "micro_f1": 0.5761882928320342}, {"micro_f1_no_misc": 0.7681050656660413, "micro_f1": 0.609058231488138}, {"micro_f1_no_misc": 0.7697608431293069, "micro_f1": 0.6329470717193861}], "total": {"test_micro_f1_no_misc": 76.02380140354342, "test_micro_f1_no_misc_se": 1.1923435353432679, "test_micro_f1": 61.86487329723661, "test_micro_f1_se": 1.4039829296536}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.7824822823914228, "micro_f1": 0.7159918438683367}, {"micro_f1_no_misc": 0.7571164510166358, "micro_f1": 0.6477320898685883}, {"micro_f1_no_misc": 0.7655874190564291, "micro_f1": 0.6369196552682792}, {"micro_f1_no_misc": 0.7986277873070325, "micro_f1": 0.668386045880277}, {"micro_f1_no_misc": 0.7774154796636348, "micro_f1": 0.6790257104194859}, {"micro_f1_no_misc": 0.7610745418964597, "micro_f1": 0.6073380171740828}, {"micro_f1_no_misc": 0.7627573858549687, "micro_f1": 0.6929019093426614}, {"micro_f1_no_misc": 0.7627800114876508, "micro_f1": 0.695679012345679}, {"micro_f1_no_misc": 0.7654751525719267, "micro_f1": 0.6136008337675872}, {"micro_f1_no_misc": 0.7477820025348543, "micro_f1": 0.6115882753919563}], "total": {"test_micro_f1_no_misc": 76.81098513781015, "test_micro_f1_no_misc_se": 0.8954333540606094, "test_micro_f1": 65.69163393326934, "test_micro_f1_se": 2.4253449333203947}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.6288006756756757, "micro_f1": 0.4609518800946621}, {"micro_f1_no_misc": 0.5833160836265784, "micro_f1": 0.29580826888188677}, {"micro_f1_no_misc": 0.6592689295039165, "micro_f1": 0.4891631979331132}, {"micro_f1_no_misc": 0.6639344262295082, "micro_f1": 0.39548787366046245}, {"micro_f1_no_misc": 0.633589370977787, "micro_f1": 0.4689637372564201}, {"micro_f1_no_misc": 0.5818248984115256, "micro_f1": 0.4383936342160885}, {"micro_f1_no_misc": 0.6366125974299559, "micro_f1": 0.5264684554024656}, {"micro_f1_no_misc": 0.6411549037580201, "micro_f1": 0.40442017020195603}, {"micro_f1_no_misc": 0.6501885211562631, "micro_f1": 0.42519685039370075}, {"micro_f1_no_misc": 0.6741331035968124, "micro_f1": 0.4139367982405371}], "total": {"test_micro_f1_no_misc": 63.528235103660414, "test_micro_f1_no_misc_se": 1.9344844931972596, "test_micro_f1": 43.18790866281293, "test_micro_f1_se": 3.890034338092833}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "fone", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.7759022661568592, "micro_f1": 0.6104053236539625}, {"micro_f1_no_misc": 0.8030247813411079, "micro_f1": 0.7135726170667934}, {"micro_f1_no_misc": 0.7606028741675429, "micro_f1": 0.6372827114699251}, {"micro_f1_no_misc": 0.7769230769230769, "micro_f1": 0.6579007721122239}, {"micro_f1_no_misc": 0.803743513713862, "micro_f1": 0.6972933900891495}, {"micro_f1_no_misc": 0.8138953219082908, "micro_f1": 0.7275531742165937}, {"micro_f1_no_misc": 0.8054876902837813, "micro_f1": 0.7175609756097561}, {"micro_f1_no_misc": 0.781445805667259, "micro_f1": 0.6970042331488114}, {"micro_f1_no_misc": 0.7910433719070468, "micro_f1": 0.7099595676210909}, {"micro_f1_no_misc": 0.8057858853878754, "micro_f1": 0.7269885662581229}], "total": {"test_micro_f1_no_misc": 79.178545874567, "test_micro_f1_no_misc_se": 1.072522931669977, "test_micro_f1": 68.9552133124643, "test_micro_f1_se": 2.5080757278851347}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "germeval", "task": "named-entity-recognition", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.7081732001024852, "micro_f1": 0.547845142439737}, {"micro_f1_no_misc": 0.7073652990608008, "micro_f1": 0.5915492957746479}, {"micro_f1_no_misc": 0.704390243902439, "micro_f1": 0.5356371490280778}, {"micro_f1_no_misc": 0.6895287958115184, "micro_f1": 0.4850190365833471}, {"micro_f1_no_misc": 0.679681479578731, "micro_f1": 0.5057856783498239}, {"micro_f1_no_misc": 0.7042253521126761, "micro_f1": 0.5343380715876007}, {"micro_f1_no_misc": 0.6941580756013745, "micro_f1": 0.5195130683852489}, {"micro_f1_no_misc": 0.7415910304324612, "micro_f1": 0.5519223859144807}, {"micro_f1_no_misc": 0.7087789107187267, "micro_f1": 0.4917765836183032}, {"micro_f1_no_misc": 0.687018701870187, "micro_f1": 0.5061728395061729}], "total": {"test_micro_f1_no_misc": 70.249110891914, "test_micro_f1_no_misc_se": 1.059152697532501, "test_micro_f1": 52.6955925118744, "test_micro_f1_se": 1.991718318665086}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "conll-nl", "task": "named-entity-recognition", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.700813786500718, "micro_f1": 0.5102968708210752}, {"micro_f1_no_misc": 0.6301663982823403, "micro_f1": 0.5387247278382581}, {"micro_f1_no_misc": 0.7024205030849551, "micro_f1": 0.4939040207522698}, {"micro_f1_no_misc": 0.6680476437079234, "micro_f1": 0.6224991800590357}, {"micro_f1_no_misc": 0.6761391474767271, "micro_f1": 0.529861307670535}, {"micro_f1_no_misc": 0.6602502406159769, "micro_f1": 0.4643828167482327}, {"micro_f1_no_misc": 0.6280579131303046, "micro_f1": 0.5084057971014493}, {"micro_f1_no_misc": 0.629845990440786, "micro_f1": 0.4775330396475771}, {"micro_f1_no_misc": 0.6946651532349603, "micro_f1": 0.45051006341328925}, {"micro_f1_no_misc": 0.6790648246546227, "micro_f1": 0.49724473257698537}], "total": {"test_micro_f1_no_misc": 66.69471601129315, "test_micro_f1_no_misc_se": 1.8120643230072182, "test_micro_f1": 50.93362556628706, "test_micro_f1_se": 2.9917910341412073}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "conll-en", "task": "named-entity-recognition", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"micro_f1_no_misc": 0.7964583962169232, "micro_f1": 0.7474350205198359}, {"micro_f1_no_misc": 0.8277242825817525, "micro_f1": 0.7650867236831587}, {"micro_f1_no_misc": 0.8351895371411054, "micro_f1": 0.7588035462755821}, {"micro_f1_no_misc": 0.7901501030118709, "micro_f1": 0.7531130665781173}, {"micro_f1_no_misc": 0.8038422649140546, "micro_f1": 0.7556283964461312}, {"micro_f1_no_misc": 0.8099240506329114, "micro_f1": 0.7542058493658872}, {"micro_f1_no_misc": 0.7953294095310423, "micro_f1": 0.7523560624059555}, {"micro_f1_no_misc": 0.8172573798005726, "micro_f1": 0.7607535845281761}, {"micro_f1_no_misc": 0.7981295393493184, "micro_f1": 0.7711408230595589}, {"micro_f1_no_misc": 0.8023997714503381, "micro_f1": 0.7548537823249819}], "total": {"test_micro_f1_no_misc": 80.7640473462989, "test_micro_f1_no_misc_se": 0.9181305511854405, "test_micro_f1": 75.73376855187387, "test_micro_f1_se": 0.4254288259188317}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6052673813284362, "macro_f1": 0.7933370671507755}, {"mcc": 0.5809857963834911, "macro_f1": 0.7861801796851389}, {"mcc": 0.573022807629616, "macro_f1": 0.7864886896805428}, {"mcc": 0.580014569051768, "macro_f1": 0.7800441545331602}, {"mcc": 0.5955008265112068, "macro_f1": 0.7932114982461682}, {"mcc": 0.5921669374661223, "macro_f1": 0.795147463655751}, {"mcc": 0.5423963486995788, "macro_f1": 0.7605458373716165}, {"mcc": 0.6124000969109954, "macro_f1": 0.8035190615835777}, {"mcc": 0.6079781577493398, "macro_f1": 0.7998733283871085}, {"mcc": 0.5858071021485919, "macro_f1": 0.7924495413215937}], "total": {"test_mcc": 58.75540023879145, "test_mcc_se": 1.2712454612347672, "test_macro_f1": 78.90796821615433, "test_macro_f1_se": 0.7504269387237839}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.49312387457871515, "macro_f1": 0.726027397260274}, {"mcc": 0.5390364285782555, "macro_f1": 0.7643418528374281}, {"mcc": 0.5391062948573124, "macro_f1": 0.7695171824452176}, {"mcc": 0.5170103114168185, "macro_f1": 0.7435442389667548}, {"mcc": 0.5278022645213255, "macro_f1": 0.7633285739526576}, {"mcc": 0.5352342574907712, "macro_f1": 0.7661296179500411}, {"mcc": 0.5519338356063954, "macro_f1": 0.7716340076612884}, {"mcc": 0.5189470838963615, "macro_f1": 0.735110361310277}, {"mcc": 0.5489335383845133, "macro_f1": 0.7573756629819672}, {"mcc": 0.49059283148192534, "macro_f1": 0.7449350138969932}], "total": {"test_mcc": 52.617207208123936, "test_mcc_se": 1.3218538891173817, "test_macro_f1": 75.41943909262899, "test_macro_f1_se": 0.9766501027446436}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb", "no"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.4476829933469412, "macro_f1": 0.6877843906329664}, {"mcc": 0.4930696045697855, "macro_f1": 0.7085206164046386}, {"mcc": 0.5315624942903422, "macro_f1": 0.7573248313877595}, {"mcc": 0.4994172696660145, "macro_f1": 0.7161692950271761}, {"mcc": 0.5133816315797659, "macro_f1": 0.7547557893670842}, {"mcc": 0.5088169206473526, "macro_f1": 0.7390873015873016}, {"mcc": 0.496945728011358, "macro_f1": 0.7170514960286243}, {"mcc": 0.4953502713730424, "macro_f1": 0.7184879725085911}, {"mcc": 0.49770347789181424, "macro_f1": 0.7321441294772051}, {"mcc": 0.5284480617404265, "macro_f1": 0.7526320388506967}], "total": {"test_mcc": 50.123784531168425, "test_mcc_se": 1.4415779664149233, "test_macro_f1": 72.83957861272043, "test_macro_f1_se": 1.4115850732352515}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.2770047187938718, "macro_f1": 0.5802971607010845}, {"mcc": 0.3273295440134144, "macro_f1": 0.6305293294533352}, {"mcc": 0.38517450831414896, "macro_f1": 0.6764272435281469}, {"mcc": 0.3249410634882708, "macro_f1": 0.6123940955883984}, {"mcc": 0.3733892604532678, "macro_f1": 0.6839553810917292}, {"mcc": 0.3688289766731806, "macro_f1": 0.6794189623532798}, {"mcc": 0.44486571698655386, "macro_f1": 0.6969571780408358}, {"mcc": 0.3318821879584702, "macro_f1": 0.6058657841362389}, {"mcc": 0.35898114062267333, "macro_f1": 0.6450792633271963}, {"mcc": 0.3549100715411123, "macro_f1": 0.6735847607343114}], "total": {"test_mcc": 35.473071888449645, "test_mcc_se": 2.757792429482847, "test_macro_f1": 64.84509158954556, "test_macro_f1_se": 2.45134139374648}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.17116291571776546, "macro_f1": 0.54890349521222}, {"mcc": 0.1679353774562332, "macro_f1": 0.5632504277531183}, {"mcc": 0.13851555463319618, "macro_f1": 0.5459835841991718}, {"mcc": 0.19776997605497065, "macro_f1": 0.5725046188829409}, {"mcc": 0.18103412681199987, "macro_f1": 0.590280356003839}, {"mcc": 0.1926810434840965, "macro_f1": 0.5962993148127043}, {"mcc": 0.15475280474931122, "macro_f1": 0.5569817577145885}, {"mcc": 0.18252958994427784, "macro_f1": 0.591111183201309}, {"mcc": 0.19285638492641524, "macro_f1": 0.5827875465712962}, {"mcc": 0.15191589690157026, "macro_f1": 0.5759579484507851}], "total": {"test_mcc": 17.311536706798364, "test_mcc_se": 1.2302979972313646, "test_macro_f1": 57.24060232801973, "test_macro_f1_se": 1.1188823251782973}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.15405253422784626, "macro_f1": 0.4891001827191115}, {"mcc": 0.0905947584159221, "macro_f1": 0.507034412285871}, {"mcc": 0.10919240791831487, "macro_f1": 0.5537071069373727}, {"mcc": 0.14738275605317597, "macro_f1": 0.501706367580731}, {"mcc": 0.1687699557916418, "macro_f1": 0.5752905933310046}, {"mcc": 0.1670659507190718, "macro_f1": 0.538486335874963}, {"mcc": 0.10509995956418015, "macro_f1": 0.3911794965071534}, {"mcc": 0.17949676824587357, "macro_f1": 0.5509282570208066}, {"mcc": 0.10106096437769434, "macro_f1": 0.44024916646985707}, {"mcc": 0.0653659739467138, "macro_f1": 0.5258225125620448}], "total": {"test_mcc": 12.880820292604348, "test_mcc_se": 2.4282714424605873, "test_macro_f1": 50.735044312889165, "test_macro_f1_se": 3.477905660574617}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-de", "task": "linguistic-acceptability", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.4484465494499253, "macro_f1": 0.7133903223733118}, {"mcc": 0.455413538269534, "macro_f1": 0.7206861445667416}, {"mcc": 0.44407968232395617, "macro_f1": 0.709548278272047}, {"mcc": 0.415183297470613, "macro_f1": 0.7043275362879102}, {"mcc": 0.4693075140657788, "macro_f1": 0.7298232891021431}, {"mcc": 0.4644687220843259, "macro_f1": 0.7119969260235282}, {"mcc": 0.43728126906165127, "macro_f1": 0.7098982423681777}, {"mcc": 0.44182846373793566, "macro_f1": 0.7127619296773091}, {"mcc": 0.381440670884009, "macro_f1": 0.6868852726152099}, {"mcc": 0.4313968005090274, "macro_f1": 0.7000401926522382}], "total": {"test_mcc": 43.88846507856757, "test_mcc_se": 1.5870201535207265, "test_macro_f1": 70.99358133938617, "test_macro_f1_se": 0.7145284081795292}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-nl", "task": "linguistic-acceptability", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6182209632117571, "macro_f1": 0.8089898119853187}, {"mcc": 0.5643527343878418, "macro_f1": 0.7821733821733822}, {"mcc": 0.5847640632472655, "macro_f1": 0.7837741197981484}, {"mcc": 0.5760076322827665, "macro_f1": 0.7868492036389727}, {"mcc": 0.5689947106054641, "macro_f1": 0.7782002839883517}, {"mcc": 0.5973969314571134, "macro_f1": 0.7981806561731017}, {"mcc": 0.598160136265039, "macro_f1": 0.7988049081744091}, {"mcc": 0.6017093578890059, "macro_f1": 0.8007622492074211}, {"mcc": 0.5818577412378846, "macro_f1": 0.788286373921733}, {"mcc": 0.5721980834630201, "macro_f1": 0.7855315778864744}], "total": {"test_mcc": 58.63662354047159, "test_mcc_se": 1.059166422954612, "test_macro_f1": 79.11552566947313, "test_macro_f1_se": 0.6127500405699037}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scala-en", "task": "linguistic-acceptability", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.5055737347705554, "macro_f1": 0.7402621635490041}, {"mcc": 0.5064820886327628, "macro_f1": 0.7386879145436342}, {"mcc": 0.5085124519652598, "macro_f1": 0.7462270064238898}, {"mcc": 0.4909625359290887, "macro_f1": 0.7231803144147233}, {"mcc": 0.47292784913943176, "macro_f1": 0.7254528639668762}, {"mcc": 0.5606668876729534, "macro_f1": 0.7765699270207999}, {"mcc": 0.533269038000775, "macro_f1": 0.743878643085043}, {"mcc": 0.5727883196193978, "macro_f1": 0.7771422159414645}, {"mcc": 0.4920824895003418, "macro_f1": 0.7306975935871121}, {"mcc": 0.5103229155181405, "macro_f1": 0.7368391665136657}], "total": {"test_mcc": 51.53588310748708, "test_mcc_se": 1.9442430737168312, "test_macro_f1": 74.38937809046212, "test_macro_f1_se": 1.1708974441424103}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scandiqa-da", "task": "reading-comprehension", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"f1": 62.4262265512264, "em": 49.31818181818182}, {"f1": 62.5921513412035, "em": 50.34116755117513}, {"f1": 64.21522921522913, "em": 54.46775446775447}, {"f1": 63.70805247517561, "em": 52.054794520547944}, {"f1": 65.959173183537, "em": 56.437933693138014}, {"f1": 63.74918211559419, "em": 52.213740458015266}, {"f1": 61.42411410742133, "em": 48.4399375975039}, {"f1": 62.287026528585486, "em": 49.685534591194966}, {"f1": 64.19467787114844, "em": 55.26315789473684}, {"f1": 63.34049823633146, "em": 51.92901234567901}], "total": {"test_f1": 63.38963316254525, "test_f1_se": 0.7950413948927731, "test_em": 52.01512149379274, "test_em_se": 1.6587382637867323}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "norquad", "task": "reading-comprehension", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"f1": 73.42519335871114, "em": 44.36274509803921}, {"f1": 70.15547687314789, "em": 41.13821138211382}, {"f1": 72.65843426889558, "em": 43.38051623646961}, {"f1": 70.70266483117611, "em": 40.71954210956664}, {"f1": 74.50132485593207, "em": 46.319272125723735}, {"f1": 69.04248771232172, "em": 39.09465020576132}, {"f1": 70.39191091448093, "em": 41.51260504201681}, {"f1": 71.99514434999878, "em": 42.652027027027025}, {"f1": 70.05384552352098, "em": 38.538205980066444}, {"f1": 70.79415960233757, "em": 40.645695364238414}], "total": {"test_f1": 71.37206422905227, "test_f1_se": 1.062306136455479, "test_em": 41.8363470571023, "test_em_se": 1.4780479392659167}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "scandiqa-sv", "task": "reading-comprehension", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"f1": 66.13362193362182, "em": 57.121212121212125}, {"f1": 63.492105349902616, "em": 52.31235784685368}, {"f1": 64.94520294520281, "em": 54.54545454545455}, {"f1": 63.95077651926953, "em": 52.8158295281583}, {"f1": 63.290009912985866, "em": 51.50346954510409}, {"f1": 63.12777171937468, "em": 53.12977099236641}, {"f1": 64.10760716142919, "em": 52.106084243369736}, {"f1": 65.88387241689115, "em": 56.367924528301884}, {"f1": 66.63106295149629, "em": 56.96594427244582}, {"f1": 65.27538947677826, "em": 56.25}], "total": {"test_f1": 64.68374203869521, "test_f1_se": 0.7841533165935465, "test_em": 54.311804762326666, "test_em_se": 1.3604547976326293}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "nqii", "task": "reading-comprehension", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"f1": 55.72981165113153, "em": 27.384615384615383}, {"f1": 58.795908394857946, "em": 28.97196261682243}, {"f1": 51.823001462794096, "em": 26.635514018691588}, {"f1": 50.50470409964408, "em": 23.766816143497756}, {"f1": 53.782244361214524, "em": 25.391849529780565}, {"f1": 53.501177423929306, "em": 27.272727272727273}, {"f1": 57.23443592324157, "em": 28.307692307692307}, {"f1": 51.03765018917636, "em": 26.687116564417177}, {"f1": 53.139244739823276, "em": 23.49397590361446}, {"f1": 54.697850803022504, "em": 30.72289156626506}], "total": {"test_f1": 54.02460290488352, "test_f1_se": 1.648998031414956, "test_em": 26.8635161308124, "test_em_se": 1.386810229126002}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "foqa", "task": "reading-comprehension", "dataset_languages": ["fo"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"f1": 80.7876497055639, "em": 59.55882352941177}, {"f1": 81.09772662560927, "em": 61.42506142506142}, {"f1": 79.44078855253824, "em": 59.01234567901235}, {"f1": 77.48821364719423, "em": 57.76699029126213}, {"f1": 80.59223631957485, "em": 62.12871287128713}, {"f1": 79.75703500125016, "em": 60.74074074074074}, {"f1": 80.66223753905864, "em": 63.20754716981132}, {"f1": 79.63374400261414, "em": 56.99745547073791}, {"f1": 80.65380030835891, "em": 62.8428927680798}, {"f1": 79.70415905368887, "em": 58.72235872235872}], "total": {"test_f1": 79.98175907554511, "test_f1_se": 0.651413344231093, "test_em": 60.24029286677633, "test_em_se": 1.3342720357771523}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "germanquad", "task": "reading-comprehension", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"f1": 53.648341674432885, "em": 25.833333333333332}, {"f1": 51.65184691164211, "em": 23.502653525398028}, {"f1": 57.00822735009266, "em": 27.03962703962704}, {"f1": 54.08415114558655, "em": 26.484018264840184}, {"f1": 53.4092224742126, "em": 26.214340786430224}, {"f1": 53.48960348915616, "em": 25.34351145038168}, {"f1": 51.41871613485475, "em": 25.117004680187208}, {"f1": 53.877787595653345, "em": 25.0}, {"f1": 52.49036084663216, "em": 22.60061919504644}, {"f1": 49.36854923529997, "em": 23.45679012345679}], "total": {"test_f1": 53.04468068575632, "test_f1_se": 1.2496352505206594, "test_em": 25.059189839870093, "test_em_se": 0.9007636279618858}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "squad", "task": "reading-comprehension", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"f1": 81.18385928891104, "em": 60.303030303030305}, {"f1": 80.80629092454922, "em": 57.7710386656558}, {"f1": 82.92339550117357, "em": 62.004662004662}, {"f1": 81.20150739435888, "em": 58.9041095890411}, {"f1": 81.3241133963339, "em": 60.44718581341557}, {"f1": 79.88679072104938, "em": 58.396946564885496}, {"f1": 80.27949910834106, "em": 56.552262090483616}, {"f1": 79.37030456327328, "em": 54.716981132075475}, {"f1": 80.75281237895993, "em": 57.585139318885446}, {"f1": 79.89089668846114, "em": 56.17283950617284}], "total": {"test_f1": 80.76194699654113, "test_f1_se": 0.6217047918311358, "test_em": 58.28541949883076, "test_em_se": 1.3693144842769818}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "squad-nl", "task": "reading-comprehension", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"f1": 74.72157171655803, "em": 50.15151515151515}, {"f1": 74.926315715167, "em": 49.73464746019712}, {"f1": 75.7131175597511, "em": 53.45765345765346}, {"f1": 73.58742516065135, "em": 49.31506849315068}, {"f1": 75.1801283446229, "em": 50.34695451040864}, {"f1": 76.33357247950846, "em": 52.74809160305343}, {"f1": 73.87703600386908, "em": 49.921996879875195}, {"f1": 76.81744367707775, "em": 54.009433962264154}, {"f1": 75.62583568355419, "em": 53.250773993808046}, {"f1": 74.91668919135643, "em": 50.23148148148148}], "total": {"test_f1": 75.16991355321163, "test_f1_se": 0.622272898465154, "test_em": 51.31676169934074, "test_em_se": 1.1231710030233073}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "nordjylland-news", "task": "summarization", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"bertscore": 0.6719954776053783, "rouge_l": 0.20488772132360433}, {"bertscore": 0.670857930323109, "rouge_l": 0.2061558544162784}, {"bertscore": 0.6662547701271251, "rouge_l": 0.19491094453608537}, {"bertscore": 0.6699562784051523, "rouge_l": 0.20444267812305367}, {"bertscore": 0.67417691895389, "rouge_l": 0.21263091363652753}, {"bertscore": 0.6683019562915433, "rouge_l": 0.19921423391896567}, {"bertscore": 0.6715604633791372, "rouge_l": 0.20439832224151516}, {"bertscore": 0.6664859314623754, "rouge_l": 0.19251501752198252}, {"bertscore": 0.671898534434149, "rouge_l": 0.2046086290422522}, {"bertscore": 0.6750490669655846, "rouge_l": 0.21354886405698148}], "total": {"test_bertscore": 67.06537327947444, "test_bertscore_se": 0.1832646073637137, "test_rouge_l": 20.37313178817246, "test_rouge_l_se": 0.41758769621391983}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mlsum", "task": "summarization", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"bertscore": 0.6532682172255591, "rouge_l": 0.16143060777980411}, {"bertscore": 0.6520684205461293, "rouge_l": 0.16050798954264553}, {"bertscore": 0.6521646722685546, "rouge_l": 0.16157515044958778}, {"bertscore": 0.6519108209467959, "rouge_l": 0.16423706450041617}, {"bertscore": 0.6520660134410718, "rouge_l": 0.15816929110762487}, {"bertscore": 0.649794585959171, "rouge_l": 0.15334049606519268}, {"bertscore": 0.6538863668974955, "rouge_l": 0.1633135395767909}, {"bertscore": 0.653905480488902, "rouge_l": 0.15934338980781299}, {"bertscore": 0.6529813743982231, "rouge_l": 0.1590721181126506}, {"bertscore": 0.6507499968429329, "rouge_l": 0.15605172719453272}], "total": {"test_bertscore": 65.22795949014835, "test_bertscore_se": 0.08120657779188348, "test_rouge_l": 15.970413741370585, "test_rouge_l_se": 0.2039239024944669}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "rrn", "task": "summarization", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"bertscore": 0.6915973096038215, "rouge_l": 0.21889731482397914}, {"bertscore": 0.6901725676143542, "rouge_l": 0.21483400615547402}, {"bertscore": 0.6910753626725636, "rouge_l": 0.2238977860904976}, {"bertscore": 0.6871293929289095, "rouge_l": 0.2116293522012115}, {"bertscore": 0.6901056417846121, "rouge_l": 0.21387905552726857}, {"bertscore": 0.6887852447689511, "rouge_l": 0.22053561834074673}, {"bertscore": 0.6868821663083509, "rouge_l": 0.21357913228170203}, {"bertscore": 0.6856259665219113, "rouge_l": 0.20587566135682128}, {"bertscore": 0.6866960648039822, "rouge_l": 0.20974627096206472}, {"bertscore": 0.6876392698613927, "rouge_l": 0.21734144577420655}], "total": {"test_bertscore": 68.85708986868849, "test_bertscore_se": 0.12799922619506648, "test_rouge_l": 21.50215643513972, "test_rouge_l_se": 0.3305633442120607}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "no-sammendrag", "task": "summarization", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"bertscore": 0.6475557150115492, "rouge_l": 0.1534699288819186}, {"bertscore": 0.6485864652349846, "rouge_l": 0.15959246806009497}, {"bertscore": 0.6487637617392465, "rouge_l": 0.15832833494466478}, {"bertscore": 0.6493577323417412, "rouge_l": 0.16196217836503052}, {"bertscore": 0.6488389378646389, "rouge_l": 0.15682129647849602}, {"bertscore": 0.6454967630415922, "rouge_l": 0.1520647257876867}, {"bertscore": 0.6441188651515404, "rouge_l": 0.14537310572204443}, {"bertscore": 0.6475972452608403, "rouge_l": 0.15538550943563303}, {"bertscore": 0.6473188160889549, "rouge_l": 0.15578385926145694}, {"bertscore": 0.6426114873611368, "rouge_l": 0.14603346394308142}], "total": {"test_bertscore": 64.70245789096225, "test_bertscore_se": 0.13882241497501405, "test_rouge_l": 15.448148708801074, "test_rouge_l_se": 0.33699902041905333}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "wiki-lingua-nl", "task": "summarization", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"bertscore": 0.666073769913055, "rouge_l": 0.18590113499907424}, {"bertscore": 0.6597232882777462, "rouge_l": 0.17704768672077142}, {"bertscore": 0.6653528808965348, "rouge_l": 0.18395704479525365}, {"bertscore": 0.6497892035695259, "rouge_l": 0.16617451870103128}, {"bertscore": 0.6554525774263311, "rouge_l": 0.16830730863530224}, {"bertscore": 0.6513827716262313, "rouge_l": 0.1688292196833553}, {"bertscore": 0.6504680125217419, "rouge_l": 0.16782928872566977}, {"bertscore": 0.6585216494713677, "rouge_l": 0.17497126869008078}, {"bertscore": 0.6512233856774401, "rouge_l": 0.1669772310222971}, {"bertscore": 0.6511237888043979, "rouge_l": 0.1720163818822619}], "total": {"test_bertscore": 65.59111328184372, "test_bertscore_se": 0.3845734809926517, "test_rouge_l": 17.320110838550974, "test_rouge_l_se": 0.44134724237617484}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "swedn", "task": "summarization", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"bertscore": 0.6665192609361839, "rouge_l": 0.18665316003342752}, {"bertscore": 0.6686792806431185, "rouge_l": 0.19187484017034057}, {"bertscore": 0.6667379366990644, "rouge_l": 0.1902214478159217}, {"bertscore": 0.6662023498211056, "rouge_l": 0.18911215410761245}, {"bertscore": 0.6689550864102785, "rouge_l": 0.1966435405678033}, {"bertscore": 0.665649685804965, "rouge_l": 0.19295564454323466}, {"bertscore": 0.667754405643791, "rouge_l": 0.19268309607922177}, {"bertscore": 0.6670048841915559, "rouge_l": 0.18946849753610753}, {"bertscore": 0.6665999200195074, "rouge_l": 0.18922661813859537}, {"bertscore": 0.6671891013684217, "rouge_l": 0.19032878936802003}], "total": {"test_bertscore": 66.71291911537992, "test_bertscore_se": 0.06533267774672426, "test_rouge_l": 19.091677883602852, "test_rouge_l_se": 0.170630137310303}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "cnn-dailymail", "task": "summarization", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"bertscore": 0.6921715271600988, "rouge_l": 0.2429184102742475}, {"bertscore": 0.6913016173639335, "rouge_l": 0.23790654329389266}, {"bertscore": 0.6912043302145321, "rouge_l": 0.23114585041195934}, {"bertscore": 0.6908097896084655, "rouge_l": 0.22741432535637024}, {"bertscore": 0.6896655130840372, "rouge_l": 0.2329392494459562}, {"bertscore": 0.691933727794094, "rouge_l": 0.23832330789055053}, {"bertscore": 0.6915283128910232, "rouge_l": 0.23818193808163302}, {"bertscore": 0.689923987549264, "rouge_l": 0.23056700531998026}, {"bertscore": 0.6914340708462987, "rouge_l": 0.23905227580674937}, {"bertscore": 0.6919425434898585, "rouge_l": 0.23809199090668992}], "total": {"test_bertscore": 69.11915420001606, "test_bertscore_se": 0.05202487356113254, "test_rouge_l": 23.56540896788029, "test_rouge_l_se": 0.2996204032149766}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "danske-talemaader", "task": "knowledge", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.7553796385828864, "accuracy": 0.8168316831683168}, {"mcc": 0.8152109372606644, "accuracy": 0.8613861386138614}, {"mcc": 0.7760868821470008, "accuracy": 0.8316831683168316}, {"mcc": 0.7774654506440846, "accuracy": 0.8329207920792079}, {"mcc": 0.7629367833351951, "accuracy": 0.8217821782178217}, {"mcc": 0.7764238379398978, "accuracy": 0.8316831683168316}, {"mcc": 0.7834900132440862, "accuracy": 0.8378712871287128}, {"mcc": 0.7443059440752365, "accuracy": 0.8081683168316832}, {"mcc": 0.7447370052967562, "accuracy": 0.8081683168316832}, {"mcc": 0.7525355046981153, "accuracy": 0.8143564356435643}], "total": {"test_mcc": 76.88571997223923, "test_mcc_se": 1.3411732213971108, "test_accuracy": 82.64851485148516, "test_accuracy_se": 1.0071944902072347}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "danish-citizen-tests", "task": "knowledge", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.9324550745046045, "accuracy": 0.955078125}, {"mcc": 0.9007330966555352, "accuracy": 0.93359375}, {"mcc": 0.9025442358968513, "accuracy": 0.935546875}, {"mcc": 0.9503311419078156, "accuracy": 0.966796875}, {"mcc": 0.9324186844605576, "accuracy": 0.955078125}, {"mcc": 0.9068251938415686, "accuracy": 0.9375}, {"mcc": 0.9145015055371242, "accuracy": 0.943359375}, {"mcc": 0.9122362777872854, "accuracy": 0.94140625}, {"mcc": 0.90261062080823, "accuracy": 0.935546875}, {"mcc": 0.9268191052653921, "accuracy": 0.951171875}], "total": {"test_mcc": 91.81474936664966, "test_mcc_se": 1.0296801313403012, "test_accuracy": 94.55078125, "test_accuracy_se": 0.6834867971888143}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu-no", "task": "knowledge", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6079623298930033, "accuracy": 0.70556640625}, {"mcc": 0.6057573551246683, "accuracy": 0.70361328125}, {"mcc": 0.5962579643699979, "accuracy": 0.69677734375}, {"mcc": 0.5934341518708305, "accuracy": 0.69482421875}, {"mcc": 0.5913259120754891, "accuracy": 0.69287109375}, {"mcc": 0.5973984881829292, "accuracy": 0.69775390625}, {"mcc": 0.5837743408327666, "accuracy": 0.68701171875}, {"mcc": 0.6065487293309363, "accuracy": 0.7041015625}, {"mcc": 0.6261106179821804, "accuracy": 0.71826171875}, {"mcc": 0.58925151669931, "accuracy": 0.69140625}], "total": {"test_mcc": 59.97821406362112, "test_mcc_se": 0.7559053118989816, "test_accuracy": 69.921875, "test_accuracy_se": 0.5558476167794795}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu-sv", "task": "knowledge", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6350963451858674, "accuracy": 0.7265625}, {"mcc": 0.6328150216750288, "accuracy": 0.7236328125}, {"mcc": 0.6285414281912255, "accuracy": 0.72021484375}, {"mcc": 0.6114756174222804, "accuracy": 0.7080078125}, {"mcc": 0.6309170253738782, "accuracy": 0.72216796875}, {"mcc": 0.6089400047636795, "accuracy": 0.70654296875}, {"mcc": 0.6196477267104853, "accuracy": 0.71435546875}, {"mcc": 0.6398388934209935, "accuracy": 0.7294921875}, {"mcc": 0.6250196550978729, "accuracy": 0.71728515625}, {"mcc": 0.6452837742988773, "accuracy": 0.732421875}], "total": {"test_mcc": 62.775754921401884, "test_mcc_se": 0.7262371521268268, "test_accuracy": 72.0068359375, "test_accuracy_se": 0.5345780827617997}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu-de", "task": "knowledge", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6066155771703863, "accuracy": 0.705078125}, {"mcc": 0.6400946178722008, "accuracy": 0.73046875}, {"mcc": 0.6137543452077191, "accuracy": 0.7099609375}, {"mcc": 0.6313810472109687, "accuracy": 0.72412109375}, {"mcc": 0.6223739140439414, "accuracy": 0.71728515625}, {"mcc": 0.6211160216073207, "accuracy": 0.7158203125}, {"mcc": 0.619390007811953, "accuracy": 0.71435546875}, {"mcc": 0.6364323539579972, "accuracy": 0.72705078125}, {"mcc": 0.6240127586689018, "accuracy": 0.7177734375}, {"mcc": 0.6431918210535688, "accuracy": 0.732421875}], "total": {"test_mcc": 62.58362464604957, "test_mcc_se": 0.728135022731911, "test_accuracy": 71.943359375, "test_accuracy_se": 0.5514729668194039}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu-nl", "task": "knowledge", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6365026463384349, "accuracy": 0.72705078125}, {"mcc": 0.6461228011142242, "accuracy": 0.73388671875}, {"mcc": 0.6216926972930882, "accuracy": 0.71630859375}, {"mcc": 0.6224894310436314, "accuracy": 0.71630859375}, {"mcc": 0.5996578815726885, "accuracy": 0.69921875}, {"mcc": 0.6428531201197432, "accuracy": 0.73193359375}, {"mcc": 0.6421255635193672, "accuracy": 0.73095703125}, {"mcc": 0.6266727442764944, "accuracy": 0.71923828125}, {"mcc": 0.6102656130828471, "accuracy": 0.70703125}, {"mcc": 0.603728386718147, "accuracy": 0.7021484375}], "total": {"test_mcc": 62.52110885078665, "test_mcc_se": 1.0375259947335564, "test_accuracy": 71.8408203125, "test_accuracy_se": 0.7802462654756398}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "mmlu", "task": "knowledge", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.7385555367614359, "accuracy": 0.8037109375}, {"mcc": 0.7106126992605404, "accuracy": 0.783203125}, {"mcc": 0.7190879026326793, "accuracy": 0.7890625}, {"mcc": 0.724889706549634, "accuracy": 0.79345703125}, {"mcc": 0.7197244140186896, "accuracy": 0.78955078125}, {"mcc": 0.7069429274795895, "accuracy": 0.77978515625}, {"mcc": 0.7321803272630998, "accuracy": 0.798828125}, {"mcc": 0.7331399115188153, "accuracy": 0.7998046875}, {"mcc": 0.7188914505887106, "accuracy": 0.7890625}, {"mcc": 0.7222370609628394, "accuracy": 0.7919921875}], "total": {"test_mcc": 72.26261937036033, "test_mcc_se": 0.6149722376354817, "test_accuracy": 79.1845703125, "test_accuracy_se": 0.4603155609095847}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "arc-is", "task": "knowledge", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6163433718894099, "accuracy": 0.712890625}, {"mcc": 0.6061433701814123, "accuracy": 0.703125}, {"mcc": 0.5992662982108325, "accuracy": 0.69921875}, {"mcc": 0.6425295563042882, "accuracy": 0.732421875}, {"mcc": 0.60394737306269, "accuracy": 0.703125}, {"mcc": 0.597706744160975, "accuracy": 0.697265625}, {"mcc": 0.587380596673684, "accuracy": 0.6904296875}, {"mcc": 0.5983367671374832, "accuracy": 0.69921875}, {"mcc": 0.6292630839536479, "accuracy": 0.7216796875}, {"mcc": 0.5839867718973288, "accuracy": 0.6884765625}], "total": {"test_mcc": 60.649039334717514, "test_mcc_se": 1.1294363335253805, "test_accuracy": 70.478515625, "test_accuracy_se": 0.8545907408444245}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-da", "task": "common-sense-reasoning", "dataset_languages": ["da"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6180533246594775, "accuracy": 0.7109375}, {"mcc": 0.5880457416121427, "accuracy": 0.68310546875}, {"mcc": 0.6277642670143111, "accuracy": 0.7138671875}, {"mcc": 0.6364972789630134, "accuracy": 0.72412109375}, {"mcc": 0.5814426134347223, "accuracy": 0.6787109375}, {"mcc": 0.5920382775123479, "accuracy": 0.689453125}, {"mcc": 0.5882371440271519, "accuracy": 0.6845703125}, {"mcc": 0.6248883788499694, "accuracy": 0.71435546875}, {"mcc": 0.608562033938002, "accuracy": 0.70556640625}, {"mcc": 0.6144038461423234, "accuracy": 0.70751953125}], "total": {"test_mcc": 60.799329061534614, "test_mcc_se": 1.2009871070732403, "test_accuracy": 70.1220703125, "test_accuracy_se": 0.9822672113075918}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-no", "task": "common-sense-reasoning", "dataset_languages": ["nb", "nn", "no"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6381650801647407, "accuracy": 0.72802734375}, {"mcc": 0.6565227304303358, "accuracy": 0.74169921875}, {"mcc": 0.6580320149541928, "accuracy": 0.74267578125}, {"mcc": 0.636154485962593, "accuracy": 0.7255859375}, {"mcc": 0.6786186203575296, "accuracy": 0.7578125}, {"mcc": 0.6243819890033957, "accuracy": 0.7177734375}, {"mcc": 0.6189004353499478, "accuracy": 0.712890625}, {"mcc": 0.6688965836009378, "accuracy": 0.75}, {"mcc": 0.6610305718436336, "accuracy": 0.74560546875}, {"mcc": 0.6272722004432575, "accuracy": 0.71728515625}], "total": {"test_mcc": 64.67974712110563, "test_mcc_se": 1.2692265917272245, "test_accuracy": 73.3935546875, "test_accuracy_se": 0.9661803348546825}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-sv", "task": "common-sense-reasoning", "dataset_languages": ["sv"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6640126099578966, "accuracy": 0.74462890625}, {"mcc": 0.6685741847326355, "accuracy": 0.7490234375}, {"mcc": 0.658323070457182, "accuracy": 0.740234375}, {"mcc": 0.6614436418392367, "accuracy": 0.7431640625}, {"mcc": 0.6894322828420064, "accuracy": 0.763671875}, {"mcc": 0.632430526026129, "accuracy": 0.72265625}, {"mcc": 0.6905169117128784, "accuracy": 0.76708984375}, {"mcc": 0.6373349192727317, "accuracy": 0.724609375}, {"mcc": 0.6576722199647034, "accuracy": 0.7392578125}, {"mcc": 0.6285853704241817, "accuracy": 0.71875}], "total": {"test_mcc": 65.88325737229582, "test_mcc_se": 1.3300598286702296, "test_accuracy": 74.130859375, "test_accuracy_se": 1.0078709911159627}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "winogrande-is", "task": "common-sense-reasoning", "dataset_languages": ["is"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.41531816669587995, "accuracy": 0.7109375}, {"mcc": 0.2726585109736665, "accuracy": 0.6372767857142857}, {"mcc": 0.3170149399665663, "accuracy": 0.6629464285714286}, {"mcc": 0.36752284334309115, "accuracy": 0.6897321428571429}, {"mcc": 0.3219764430743744, "accuracy": 0.6618303571428571}, {"mcc": 0.4102823914467414, "accuracy": 0.6964285714285714}, {"mcc": 0.2982323827569502, "accuracy": 0.6551339285714286}, {"mcc": 0.293579098190651, "accuracy": 0.6495535714285714}, {"mcc": 0.3301096782804385, "accuracy": 0.6707589285714286}, {"mcc": 0.3399603957510284, "accuracy": 0.6651785714285714}], "total": {"test_mcc": 33.66654850479388, "test_mcc_se": 2.968467256350352, "test_accuracy": 66.99776785714285, "test_accuracy_se": 1.4033569778540553}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-de", "task": "common-sense-reasoning", "dataset_languages": ["de"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6866342816162577, "accuracy": 0.76318359375}, {"mcc": 0.6741959947506846, "accuracy": 0.751953125}, {"mcc": 0.689301922180001, "accuracy": 0.7646484375}, {"mcc": 0.6450654578926391, "accuracy": 0.732421875}, {"mcc": 0.6600672652957462, "accuracy": 0.7431640625}, {"mcc": 0.6654024082873096, "accuracy": 0.748046875}, {"mcc": 0.6765660357013664, "accuracy": 0.75390625}, {"mcc": 0.6371957657602431, "accuracy": 0.72265625}, {"mcc": 0.6948252461560406, "accuracy": 0.767578125}, {"mcc": 0.6706099209250426, "accuracy": 0.74951171875}], "total": {"test_mcc": 66.9986429856533, "test_mcc_se": 1.1585005654954497, "test_accuracy": 74.970703125, "test_accuracy_se": 0.8821315819817852}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag-nl", "task": "common-sense-reasoning", "dataset_languages": ["nl"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.6414651981182204, "accuracy": 0.7275390625}, {"mcc": 0.633911487265749, "accuracy": 0.720703125}, {"mcc": 0.6645985038269324, "accuracy": 0.74462890625}, {"mcc": 0.650283784791811, "accuracy": 0.734375}, {"mcc": 0.6380879646047163, "accuracy": 0.72265625}, {"mcc": 0.642754783357319, "accuracy": 0.72900390625}, {"mcc": 0.6652897608718337, "accuracy": 0.74609375}, {"mcc": 0.6668884484494462, "accuracy": 0.7470703125}, {"mcc": 0.6544921375008741, "accuracy": 0.73779296875}, {"mcc": 0.5892857727914557, "accuracy": 0.68701171875}], "total": {"test_mcc": 64.47057841578359, "test_mcc_se": 1.4140366738725603, "test_accuracy": 72.96875, "test_accuracy_se": 1.100766232967712}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "hellaswag", "task": "common-sense-reasoning", "dataset_languages": ["en"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"mcc": 0.7852823471684047, "accuracy": 0.83740234375}, {"mcc": 0.7991297251825574, "accuracy": 0.8486328125}, {"mcc": 0.8056578622660364, "accuracy": 0.8515625}, {"mcc": 0.8169633392340361, "accuracy": 0.8623046875}, {"mcc": 0.8163914562512175, "accuracy": 0.86181640625}, {"mcc": 0.8314617474116363, "accuracy": 0.87255859375}, {"mcc": 0.8229501817349228, "accuracy": 0.86669921875}, {"mcc": 0.8242948897830282, "accuracy": 0.86767578125}, {"mcc": 0.7983934486289324, "accuracy": 0.84716796875}, {"mcc": 0.7781508419527682, "accuracy": 0.83056640625}], "total": {"test_mcc": 80.78675839613541, "test_mcc_se": 1.088066756209226, "test_accuracy": 85.4638671875, "test_accuracy_se": 0.8580194214048227}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "meta-llama/Meta-Llama-3-70B-instruct", "results": {"raw": [{"test_speed": 229.33, "test_speed_short": 26.56}, {"test_speed": 446.96999999999997, "test_speed_short": 50.25}, {"test_speed": 675.2, "test_speed_short": 94.83}, {"test_speed": 882.34, "test_speed_short": 117.35999999999999}, {"test_speed": 1105.6499999999999, "test_speed_short": 141.04}, {"test_speed": 1334.57, "test_speed_short": 186.39000000000001}, {"test_speed": 1536.83, "test_speed_short": 205.44}, {"test_speed": 1542.75, "test_speed_short": 229.33}, {"test_speed": 1987.6499999999999, "test_speed_short": 250.38}, {"test_speed": 2201.14, "test_speed_short": 274.55}], "total": {"test_speed": 1194.243, "test_speed_se": 400.9286215597164, "test_speed_short": 157.613, "test_speed_short_se": 52.70469601577959}}, "num_model_parameters": 70553706496, "max_sequence_length": 8192, "vocabulary_size": 128256, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "14.3.0"}
